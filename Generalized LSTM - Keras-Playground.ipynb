{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, LSTM, Flatten\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "#import keras as keras\n",
    "#from keras import Sequential\n",
    "#from keras.layers import LSTM, Dense, LSTM, Flatten\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgomezm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "enc = pickle.load( open( \"pickle\\\\enc.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.92811562, 0.99980535, 1.81855196, 1.10213496, 1.15103641,\n",
       "       1.05299303, 1.92378277, 2.5068326 , 0.5429417 , 1.10963491,\n",
       "       0.92002508, 0.4070288 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x = pickle.load( open( \"pickle\\\\val_x.p\", \"rb\" ) )\n",
    "train_x = pickle.load( open( \"pickle\\\\train_x.p\", \"rb\" ) )\n",
    "val_labels = pickle.load( open( \"pickle\\\\val_labels.p\", \"rb\" ) )\n",
    "train_labels = pickle.load( open( \"pickle\\\\train_labels.p\", \"rb\" ) )\n",
    "class_weights = pickle.load( open( \"pickle\\\\class_weights.p\", \"rb\" ) )\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41092, 200, 27)\n",
      "41092\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41092, 200, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41092, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1776., 3425., 1883., 3107., 2975., 3252., 1780., 1366., 6307.,\n",
       "       3086., 3722., 8413.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 436.,  781.,  469.,  833.,  671.,  862.,  454.,  316., 1849.,\n",
       "        785.,  936., 2103.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(val_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2047357149810182"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.sum(train_labels, axis = 0))/sum(np.sum(train_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.200381133873273"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.sum(val_labels, axis = 0))/sum(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AU', 'CO', 'EC', 'GB', 'HK', 'JP', 'MX', 'NZ', 'TN', 'TR', 'US',\n",
       "       'ZA'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_index = 2\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(25, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = True))\n",
    "model.add(LSTM(50, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = True))\n",
    "model.add(LSTM(100, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = False))\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 25)           5300      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200, 50)           15200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1212      \n",
      "=================================================================\n",
      "Total params: 82,112\n",
      "Trainable params: 82,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41092 samples, validate on 10495 samples\n",
      "Epoch 1/5\n",
      "41092/41092 [==============================] - 185s 4ms/sample - loss: 2.3479 - acc: 0.2045 - val_loss: 2.3301 - val_acc: 0.2004\n",
      "Epoch 2/5\n",
      "41092/41092 [==============================] - 195s 5ms/sample - loss: 2.3462 - acc: 0.2047 - val_loss: 2.3332 - val_acc: 0.2004\n",
      "Epoch 3/5\n",
      "41092/41092 [==============================] - 211s 5ms/sample - loss: 2.3448 - acc: 0.2047 - val_loss: 2.3295 - val_acc: 0.2004\n",
      "Epoch 4/5\n",
      "41092/41092 [==============================] - 223s 5ms/sample - loss: 2.3450 - acc: 0.2042 - val_loss: 2.3274 - val_acc: 0.2003\n",
      "Epoch 5/5\n",
      "41092/41092 [==============================] - 228s 6ms/sample - loss: 2.3435 - acc: 0.2050 - val_loss: 2.3289 - val_acc: 0.2005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2180bbe9be0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 5, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 512,\n",
    "         class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10495/10495 [==============================] - 8s 802us/sample\n",
      "[ 419.18     818.3404   469.60016  841.30597  726.1219   797.6946\n",
      "  444.03616  303.56003 1568.2731   780.71844  935.0686  2391.2947 ]\n",
      "[ 436.  781.  469.  833.  671.  862.  454.  316. 1849.  785.  936. 2103.]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2179b740320>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 25)           5300      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200, 50)           15200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1212      \n",
      "=================================================================\n",
      "Total params: 82,112\n",
      "Trainable params: 82,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41092 samples, validate on 10495 samples\n",
      "Epoch 1/45\n",
      "41092/41092 [==============================] - 239s 6ms/sample - loss: 2.3421 - acc: 0.2053 - val_loss: 2.3273 - val_acc: 0.2017\n",
      "Epoch 2/45\n",
      "41092/41092 [==============================] - 236s 6ms/sample - loss: 2.3414 - acc: 0.2057 - val_loss: 2.3271 - val_acc: 0.2017\n",
      "Epoch 3/45\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3402 - acc: 0.2060 - val_loss: 2.3249 - val_acc: 0.2028\n",
      "Epoch 4/45\n",
      "18944/41092 [============>.................] - ETA: 2:03 - loss: 2.3322 - acc: 0.2055"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 45, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 512,\n",
    "         class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 LSTM w/ Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pop()\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[-1].trainable = True\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 20, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 512,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pop()\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[-1].trainable = True\n",
    "model.add(keras.layers.Dropout(.25))\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 20, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 512,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune full network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.pop()\n",
    "model.add(keras.layers.Dropout(.25))\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 500, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 256,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
