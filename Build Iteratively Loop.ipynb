{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, BatchNormalization, Dropout, GRU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import module\n",
    "import gc\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "              handle_unknown='error', sparse=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countriesOfInterest = {\"HK\", \"JP\", 'ZA', 'TN', 'TR', 'GB', 'MX', 'US', 'CO', 'EC', 'AU', 'NZ'}\n",
    "countriesOfInterest = [\"ZA\", \"EG\", \"TW\", \"JP\", \"DK\", \"FI\", \"US\", \"CA\", \"AU\", \"NZ\", \"BR\", \"CO\"]\n",
    "#countriesOfInterest = list(countriesOfInterest & {\"ZA\", \"EG\", \"TW\", \"JP\", \"DK\", \"FI\", \"US\", \"CA\", \"AU\", \"NZ\", \"BR\", \"CO\"})\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.array(countriesOfInterest).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "seconds = 10\n",
    "samplerate = 10\n",
    "train_x, train_labels, val_x, val_labels, class_weights = module.getSamples(1, 1, 1, 1, seconds, samplerate, countriesOfInterest,\n",
    "               enc, verbose = 0)\n",
    "print(\"train\", np.sum(train_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=(train_x.shape[1], train_x.shape[2])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 100, 25)           100       \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100, 8)            1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 8)            32        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 3,408\n",
      "Trainable params: 3,198\n",
      "Non-trainable params: 210\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 24000 samples, validate on 4800 samples\n",
      "Epoch 1/2\n",
      "24000/24000 [==============================] - 6s 239us/sample - loss: 3.1110 - acc: 0.0855 - val_loss: 2.4891 - val_acc: 0.0819\n",
      "Epoch 2/2\n",
      "24000/24000 [==============================] - 3s 139us/sample - loss: 2.9005 - acc: 0.0882 - val_loss: 2.4888 - val_acc: 0.0819\n",
      "Train on 24000 samples, validate on 4800 samples\n",
      "Epoch 3/4\n",
      "24000/24000 [==============================] - 6s 236us/sample - loss: 2.7951 - acc: 0.0861 - val_loss: 2.4891 - val_acc: 0.0871\n",
      "Epoch 4/4\n",
      "24000/24000 [==============================] - 3s 143us/sample - loss: 2.6853 - acc: 0.0865 - val_loss: 2.4886 - val_acc: 0.0808\n",
      "Train on 24000 samples, validate on 4800 samples\n",
      "Epoch 5/6\n",
      "24000/24000 [==============================] - 6s 243us/sample - loss: 2.6127 - acc: 0.0908 - val_loss: 2.4858 - val_acc: 0.0790\n",
      "Epoch 6/6\n",
      "24000/24000 [==============================] - 4s 146us/sample - loss: 2.5656 - acc: 0.0957 - val_loss: 2.4855 - val_acc: 0.0852\n",
      "Train on 24000 samples, validate on 4800 samples\n",
      "Epoch 7/8\n",
      "24000/24000 [==============================] - 6s 248us/sample - loss: 2.5487 - acc: 0.0945 - val_loss: 2.4855 - val_acc: 0.0958\n",
      "Epoch 8/8\n",
      "24000/24000 [==============================] - 4s 150us/sample - loss: 2.5210 - acc: 0.1010 - val_loss: 2.4851 - val_acc: 0.0973\n",
      "Train on 24000 samples, validate on 4800 samples\n",
      "Epoch 9/10\n",
      "24000/24000 [==============================] - 6s 248us/sample - loss: 2.5255 - acc: 0.0954 - val_loss: 2.4847 - val_acc: 0.0856\n",
      "Epoch 10/10\n",
      "24000/24000 [==============================] - 4s 157us/sample - loss: 2.5055 - acc: 0.1016 - val_loss: 2.4853 - val_acc: 0.0842\n",
      "10_seconds_10_samples iteration 5\n",
      "4800/4800 [==============================] - 1s 148us/sample\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 1s 44us/sample\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 4800 samples\n",
      "Epoch 11/12\n",
      "24000/24000 [==============================] - 6s 263us/sample - loss: 2.5005 - acc: 0.1025 - val_loss: 2.4853 - val_acc: 0.0860\n",
      "Epoch 12/12\n",
      "24000/24000 [==============================] - 4s 169us/sample - loss: 2.4845 - acc: 0.1135 - val_loss: 2.4858 - val_acc: 0.0890\n",
      "Train on 24000 samples, validate on 4800 samples\n",
      "Epoch 13/14\n",
      "24000/24000 [==============================] - 6s 260us/sample - loss: 2.4910 - acc: 0.1138 - val_loss: 2.4847 - val_acc: 0.0865\n",
      "Epoch 14/14\n",
      "24000/24000 [==============================] - 4s 163us/sample - loss: 2.4772 - acc: 0.1167 - val_loss: 2.4850 - val_acc: 0.0833\n",
      "Train on 24000 samples, validate on 4800 samples\n",
      "Epoch 15/16\n",
      "24000/24000 [==============================] - 6s 270us/sample - loss: 2.4906 - acc: 0.1050 - val_loss: 2.4821 - val_acc: 0.0840\n",
      "Epoch 16/16\n",
      "24000/24000 [==============================] - 4s 172us/sample - loss: 2.4790 - acc: 0.1098 - val_loss: 2.4815 - val_acc: 0.0900\n",
      "Train on 24000 samples, validate on 4800 samples\n",
      "Epoch 17/18\n",
      "16384/24000 [===================>..........] - ETA: 2s - loss: 2.4830 - acc: 0.1078"
     ]
    }
   ],
   "source": [
    "train_n = 100\n",
    "sample_n = train_n * 20\n",
    "val_n  = int(train_n/5)\n",
    "valsample_n = val_n * 20\n",
    "iterations = 50\n",
    "epochs = 2\n",
    "learn_rate = 0.001\n",
    "batch_size = 4096\n",
    "for D in [64]:\n",
    "    for LSTM2 in [8, 16, 32, 64]:\n",
    "        for LSTM1 in [8, 16, 32, 64]:\n",
    "            model = keras.Sequential()\n",
    "            model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "            model.add(LSTM(LSTM1, \n",
    "                           input_shape=input_shape, \n",
    "                           return_sequences = True\n",
    "                          ))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(LSTM(LSTM2, \n",
    "                           return_sequences = False,\n",
    "                           go_backwards = True\n",
    "                          ))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dense(D, activation= \"relu\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "            adam = keras.optimizers.Adam(lr=0.001, amsgrad = True)\n",
    "            model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "            gc.collect()\n",
    "            print(model.summary())\n",
    "            desc = str(LSTM1) + \"_\" + str(LSTM2) + \"_\" + str(D)\n",
    "            log_dir = os.path.join(\n",
    "                \"logs\",\n",
    "                \"10sec_10sample\",\n",
    "                desc\n",
    "            )\n",
    "            model_dir = os.path.join(\n",
    "                \"pickle\",\n",
    "                desc\n",
    "            )\n",
    "\n",
    "\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            model = module.train(iterations, learn_rate, train_n, sample_n, val_n, valsample_n, seconds, samplerate,\n",
    "                            countriesOfInterest, enc, epochs, tensorboard_callback, model_dir,\n",
    "                            model, batch_size)\n",
    "            del model, model_dir, log_dir, desc, adam\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(BatchNormalization(input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "\n",
    "model.add(LSTM(16, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = True,\n",
    "          #     recurrent_dropout = .5,\n",
    "          #     kernel_regularizer=regularizers.l2(0.01),\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(32, \n",
    "             #  input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = False,\n",
    "  #             recurrent_dropout = .5,\n",
    "               go_backwards = True\n",
    "          #     kernel_regularizer=regularizers.l2(0.01),\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(.5))\n",
    "model.add(Dense(16, activation= \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(.5))\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "adam = keras.optimizers.Adam(lr=0.001, amsgrad = True)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "del train_x, train_labels, val_x, val_labels, class_weights\n",
    "gc.collect()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add recurrent dropout to add noise to duration\n",
    "desc = \"normin_LSTM16_32_Out_1Step_001LR_amsgrad\"\n",
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    \"Overfit\",\n",
    "    desc\n",
    ")\n",
    "model_dir = os.path.join(\n",
    "    \"pickle\",\n",
    "    \"save\"\n",
    ")\n",
    "\n",
    "train_n = 100\n",
    "sample_n = 8000\n",
    "val_n  = int(2*train_n/5)\n",
    "valsample_n = 1000\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "epochs = 1\n",
    "iterations = 40\n",
    "learn_rate = 0.001\n",
    "batch_size = 4096\n",
    "model = module.train(iterations, learn_rate, train_n, sample_n, val_n, valsample_n, seconds, samplerate,\n",
    "                countriesOfInterest, enc, epochs, tensorboard_callback, model_dir,\n",
    "                model, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
