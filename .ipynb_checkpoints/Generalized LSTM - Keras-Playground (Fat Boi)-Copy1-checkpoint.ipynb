{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, LSTM, Flatten, BatchNormalization, Dropout\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "#import keras as keras\n",
    "#from keras import Sequential\n",
    "#from keras.layers import LSTM, Dense, LSTM, Flatten\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgomezm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "enc = pickle.load( open( \"pickle\\\\enc.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.92811562, 0.99980535, 1.81855196, 1.10213496, 1.15103641,\n",
       "       1.05299303, 1.92378277, 2.5068326 , 0.5429417 , 1.10963491,\n",
       "       0.92002508, 0.4070288 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x = pickle.load( open( \"pickle\\\\val_x.p\", \"rb\" ) )\n",
    "train_x = pickle.load( open( \"pickle\\\\train_x.p\", \"rb\" ) )\n",
    "val_labels = pickle.load( open( \"pickle\\\\val_labels.p\", \"rb\" ) )\n",
    "train_labels = pickle.load( open( \"pickle\\\\train_labels.p\", \"rb\" ) )\n",
    "class_weights = pickle.load( open( \"pickle\\\\class_weights.p\", \"rb\" ) )\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41092, 200, 27)\n",
      "41092\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    \"fit\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41092, 200, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41092, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1776., 3425., 1883., 3107., 2975., 3252., 1780., 1366., 6307.,\n",
       "       3086., 3722., 8413.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 436.,  781.,  469.,  833.,  671.,  862.,  454.,  316., 1849.,\n",
       "        785.,  936., 2103.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(val_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2047357149810182"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.sum(train_labels, axis = 0))/sum(np.sum(train_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.200381133873273"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.sum(val_labels, axis = 0))/sum(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AU', 'CO', 'EC', 'GB', 'HK', 'JP', 'MX', 'NZ', 'TN', 'TR', 'US',\n",
       "       'ZA'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 16)           2816      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 16)           64        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 9,676\n",
      "Trainable params: 9,580\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "out_index = 2\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(16, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(32, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41092 samples, validate on 10495 samples\n",
      "Epoch 1/100\n",
      "41092/41092 [==============================] - 34s 816us/sample - loss: 2.6612 - acc: 0.0525 - val_loss: 2.4791 - val_acc: 0.0818\n",
      "Epoch 2/100\n",
      "41092/41092 [==============================] - 33s 812us/sample - loss: 2.5866 - acc: 0.0528 - val_loss: 2.4736 - val_acc: 0.0819\n",
      "Epoch 3/100\n",
      "41092/41092 [==============================] - 35s 855us/sample - loss: 2.5491 - acc: 0.0576 - val_loss: 2.4691 - val_acc: 0.0818\n",
      "Epoch 4/100\n",
      "41092/41092 [==============================] - 36s 884us/sample - loss: 2.5222 - acc: 0.1604 - val_loss: 2.4662 - val_acc: 0.0823\n",
      "Epoch 5/100\n",
      "41092/41092 [==============================] - 38s 915us/sample - loss: 2.5046 - acc: 0.1991 - val_loss: 2.4632 - val_acc: 0.0811\n",
      "Epoch 6/100\n",
      "41092/41092 [==============================] - 40s 967us/sample - loss: 2.4931 - acc: 0.1987 - val_loss: 2.4628 - val_acc: 0.0804\n",
      "Epoch 7/100\n",
      "41092/41092 [==============================] - 43s 1ms/sample - loss: 2.4842 - acc: 0.1995 - val_loss: 2.4615 - val_acc: 0.0806\n",
      "Epoch 8/100\n",
      "41092/41092 [==============================] - 47s 1ms/sample - loss: 2.4754 - acc: 0.1993 - val_loss: 2.4598 - val_acc: 0.1629\n",
      "Epoch 9/100\n",
      "41092/41092 [==============================] - 51s 1ms/sample - loss: 2.4689 - acc: 0.2001 - val_loss: 2.4585 - val_acc: 0.1897\n",
      "Epoch 10/100\n",
      "41092/41092 [==============================] - 55s 1ms/sample - loss: 2.4615 - acc: 0.2005 - val_loss: 2.4572 - val_acc: 0.1901\n",
      "Epoch 11/100\n",
      "41092/41092 [==============================] - 59s 1ms/sample - loss: 2.4561 - acc: 0.2005 - val_loss: 2.4561 - val_acc: 0.1904\n",
      "Epoch 12/100\n",
      "41092/41092 [==============================] - 67s 2ms/sample - loss: 2.4500 - acc: 0.2008 - val_loss: 2.4529 - val_acc: 0.1924\n",
      "Epoch 13/100\n",
      "41092/41092 [==============================] - 73s 2ms/sample - loss: 2.4448 - acc: 0.2011 - val_loss: 2.4512 - val_acc: 0.1927\n",
      "Epoch 14/100\n",
      "41092/41092 [==============================] - 73s 2ms/sample - loss: 2.4396 - acc: 0.2023 - val_loss: 2.4463 - val_acc: 0.1929\n",
      "Epoch 15/100\n",
      "41092/41092 [==============================] - 77s 2ms/sample - loss: 2.4353 - acc: 0.2019 - val_loss: 2.4409 - val_acc: 0.1932\n",
      "Epoch 16/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.4294 - acc: 0.2026 - val_loss: 2.4355 - val_acc: 0.1930\n",
      "Epoch 17/100\n",
      "41092/41092 [==============================] - 79s 2ms/sample - loss: 2.4249 - acc: 0.2014 - val_loss: 2.4342 - val_acc: 0.1931\n",
      "Epoch 18/100\n",
      "41092/41092 [==============================] - 76s 2ms/sample - loss: 2.4201 - acc: 0.2023 - val_loss: 2.4275 - val_acc: 0.1929\n",
      "Epoch 19/100\n",
      "41092/41092 [==============================] - 86s 2ms/sample - loss: 2.4159 - acc: 0.2022 - val_loss: 2.4285 - val_acc: 0.1925\n",
      "Epoch 20/100\n",
      "41092/41092 [==============================] - 86s 2ms/sample - loss: 2.4112 - acc: 0.2025 - val_loss: 2.4229 - val_acc: 0.1922\n",
      "Epoch 21/100\n",
      "41092/41092 [==============================] - 85s 2ms/sample - loss: 2.4074 - acc: 0.2034 - val_loss: 2.4203 - val_acc: 0.1970\n",
      "Epoch 22/100\n",
      "41092/41092 [==============================] - 86s 2ms/sample - loss: 2.4039 - acc: 0.2030 - val_loss: 2.4162 - val_acc: 0.1995\n",
      "Epoch 23/100\n",
      "41092/41092 [==============================] - 82s 2ms/sample - loss: 2.3987 - acc: 0.2034 - val_loss: 2.4129 - val_acc: 0.1969\n",
      "Epoch 24/100\n",
      "41092/41092 [==============================] - 86s 2ms/sample - loss: 2.3958 - acc: 0.2046 - val_loss: 2.4089 - val_acc: 0.1987\n",
      "Epoch 25/100\n",
      "41092/41092 [==============================] - 86s 2ms/sample - loss: 2.3925 - acc: 0.2035 - val_loss: 2.4052 - val_acc: 0.1991\n",
      "Epoch 26/100\n",
      "41092/41092 [==============================] - 84s 2ms/sample - loss: 2.3891 - acc: 0.2041 - val_loss: 2.4013 - val_acc: 0.1985\n",
      "Epoch 27/100\n",
      "41092/41092 [==============================] - 85s 2ms/sample - loss: 2.3846 - acc: 0.2055 - val_loss: 2.3982 - val_acc: 0.1982\n",
      "Epoch 28/100\n",
      "41092/41092 [==============================] - 86s 2ms/sample - loss: 2.3821 - acc: 0.2048 - val_loss: 2.3942 - val_acc: 0.2008\n",
      "Epoch 29/100\n",
      "41092/41092 [==============================] - 86s 2ms/sample - loss: 2.3793 - acc: 0.2051 - val_loss: 2.3916 - val_acc: 0.1991\n",
      "Epoch 30/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3762 - acc: 0.2049 - val_loss: 2.3857 - val_acc: 0.2012\n",
      "Epoch 31/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3733 - acc: 0.2054 - val_loss: 2.3832 - val_acc: 0.2003\n",
      "Epoch 32/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3708 - acc: 0.2054 - val_loss: 2.3803 - val_acc: 0.2003\n",
      "Epoch 33/100\n",
      "41092/41092 [==============================] - 84s 2ms/sample - loss: 2.3680 - acc: 0.2062 - val_loss: 2.3770 - val_acc: 0.2007\n",
      "Epoch 34/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3655 - acc: 0.2055 - val_loss: 2.3749 - val_acc: 0.2000\n",
      "Epoch 35/100\n",
      "41092/41092 [==============================] - 84s 2ms/sample - loss: 2.3637 - acc: 0.2060 - val_loss: 2.3728 - val_acc: 0.1998\n",
      "Epoch 36/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3616 - acc: 0.2057 - val_loss: 2.3692 - val_acc: 0.2006\n",
      "Epoch 37/100\n",
      "41092/41092 [==============================] - 82s 2ms/sample - loss: 2.3598 - acc: 0.2065 - val_loss: 2.3668 - val_acc: 0.2007\n",
      "Epoch 38/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3577 - acc: 0.2062 - val_loss: 2.3657 - val_acc: 0.2009\n",
      "Epoch 39/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3566 - acc: 0.2060 - val_loss: 2.3631 - val_acc: 0.2010\n",
      "Epoch 40/100\n",
      "41092/41092 [==============================] - 79s 2ms/sample - loss: 2.3546 - acc: 0.2065 - val_loss: 2.3618 - val_acc: 0.2010\n",
      "Epoch 41/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3531 - acc: 0.2061 - val_loss: 2.3603 - val_acc: 0.2013\n",
      "Epoch 42/100\n",
      "41092/41092 [==============================] - 84s 2ms/sample - loss: 2.3516 - acc: 0.2065 - val_loss: 2.3591 - val_acc: 0.2003\n",
      "Epoch 43/100\n",
      "41092/41092 [==============================] - 84s 2ms/sample - loss: 2.3504 - acc: 0.2070 - val_loss: 2.3572 - val_acc: 0.2007\n",
      "Epoch 44/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3494 - acc: 0.2065 - val_loss: 2.3549 - val_acc: 0.2013\n",
      "Epoch 45/100\n",
      "41092/41092 [==============================] - 82s 2ms/sample - loss: 2.3489 - acc: 0.2063 - val_loss: 2.3535 - val_acc: 0.2007\n",
      "Epoch 46/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3480 - acc: 0.2063 - val_loss: 2.3522 - val_acc: 0.2006\n",
      "Epoch 47/100\n",
      "41092/41092 [==============================] - 84s 2ms/sample - loss: 2.3464 - acc: 0.2067 - val_loss: 2.3509 - val_acc: 0.2014\n",
      "Epoch 48/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3459 - acc: 0.2066 - val_loss: 2.3496 - val_acc: 0.2006\n",
      "Epoch 49/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3447 - acc: 0.2068 - val_loss: 2.3490 - val_acc: 0.2006\n",
      "Epoch 50/100\n",
      "41092/41092 [==============================] - 84s 2ms/sample - loss: 2.3441 - acc: 0.2059 - val_loss: 2.3471 - val_acc: 0.2008\n",
      "Epoch 51/100\n",
      "41092/41092 [==============================] - 84s 2ms/sample - loss: 2.3432 - acc: 0.2070 - val_loss: 2.3466 - val_acc: 0.2017\n",
      "Epoch 52/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3426 - acc: 0.2058 - val_loss: 2.3453 - val_acc: 0.2004\n",
      "Epoch 53/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3419 - acc: 0.2064 - val_loss: 2.3440 - val_acc: 0.2010\n",
      "Epoch 54/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3410 - acc: 0.2072 - val_loss: 2.3432 - val_acc: 0.2005\n",
      "Epoch 55/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3402 - acc: 0.2075 - val_loss: 2.3427 - val_acc: 0.2007\n",
      "Epoch 56/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3399 - acc: 0.2072 - val_loss: 2.3423 - val_acc: 0.2012\n",
      "Epoch 57/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3394 - acc: 0.2078 - val_loss: 2.3416 - val_acc: 0.2007\n",
      "Epoch 58/100\n",
      "41092/41092 [==============================] - 79s 2ms/sample - loss: 2.3393 - acc: 0.2074 - val_loss: 2.3410 - val_acc: 0.2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3386 - acc: 0.2075 - val_loss: 2.3401 - val_acc: 0.2010\n",
      "Epoch 60/100\n",
      "41092/41092 [==============================] - 84s 2ms/sample - loss: 2.3385 - acc: 0.2072 - val_loss: 2.3400 - val_acc: 0.2013\n",
      "Epoch 61/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3380 - acc: 0.2078 - val_loss: 2.3395 - val_acc: 0.2009\n",
      "Epoch 62/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3380 - acc: 0.2074 - val_loss: 2.3389 - val_acc: 0.2031\n",
      "Epoch 63/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3376 - acc: 0.2074 - val_loss: 2.3384 - val_acc: 0.2015\n",
      "Epoch 64/100\n",
      "41092/41092 [==============================] - 78s 2ms/sample - loss: 2.3370 - acc: 0.2078 - val_loss: 2.3383 - val_acc: 0.2010\n",
      "Epoch 65/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3367 - acc: 0.2077 - val_loss: 2.3381 - val_acc: 0.2017\n",
      "Epoch 66/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3366 - acc: 0.2073 - val_loss: 2.3380 - val_acc: 0.2016\n",
      "Epoch 67/100\n",
      "41092/41092 [==============================] - 78s 2ms/sample - loss: 2.3361 - acc: 0.2075 - val_loss: 2.3373 - val_acc: 0.2014\n",
      "Epoch 68/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3362 - acc: 0.2073 - val_loss: 2.3374 - val_acc: 0.2011\n",
      "Epoch 69/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3361 - acc: 0.2077 - val_loss: 2.3372 - val_acc: 0.2023\n",
      "Epoch 70/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3357 - acc: 0.2075 - val_loss: 2.3365 - val_acc: 0.2013\n",
      "Epoch 71/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3354 - acc: 0.2073 - val_loss: 2.3376 - val_acc: 0.2011\n",
      "Epoch 72/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3353 - acc: 0.2084 - val_loss: 2.3369 - val_acc: 0.2010\n",
      "Epoch 73/100\n",
      "41092/41092 [==============================] - 82s 2ms/sample - loss: 2.3352 - acc: 0.2081 - val_loss: 2.3366 - val_acc: 0.2010\n",
      "Epoch 74/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3354 - acc: 0.2081 - val_loss: 2.3372 - val_acc: 0.2017\n",
      "Epoch 75/100\n",
      "41092/41092 [==============================] - 82s 2ms/sample - loss: 2.3353 - acc: 0.2079 - val_loss: 2.3369 - val_acc: 0.2016\n",
      "Epoch 76/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3349 - acc: 0.2074 - val_loss: 2.3365 - val_acc: 0.2011\n",
      "Epoch 77/100\n",
      "41092/41092 [==============================] - 78s 2ms/sample - loss: 2.3349 - acc: 0.2083 - val_loss: 2.3367 - val_acc: 0.2012\n",
      "Epoch 78/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3348 - acc: 0.2082 - val_loss: 2.3367 - val_acc: 0.2035\n",
      "Epoch 79/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3345 - acc: 0.2079 - val_loss: 2.3357 - val_acc: 0.2018\n",
      "Epoch 80/100\n",
      "41092/41092 [==============================] - 79s 2ms/sample - loss: 2.3344 - acc: 0.2080 - val_loss: 2.3356 - val_acc: 0.2010\n",
      "Epoch 81/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3344 - acc: 0.2072 - val_loss: 2.3354 - val_acc: 0.2012\n",
      "Epoch 82/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3342 - acc: 0.2078 - val_loss: 2.3345 - val_acc: 0.2014\n",
      "Epoch 83/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3339 - acc: 0.2082 - val_loss: 2.3351 - val_acc: 0.2014\n",
      "Epoch 84/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3341 - acc: 0.2077 - val_loss: 2.3346 - val_acc: 0.2013\n",
      "Epoch 85/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3340 - acc: 0.2075 - val_loss: 2.3338 - val_acc: 0.2010\n",
      "Epoch 86/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3340 - acc: 0.2082 - val_loss: 2.3343 - val_acc: 0.2018\n",
      "Epoch 87/100\n",
      "41092/41092 [==============================] - 82s 2ms/sample - loss: 2.3338 - acc: 0.2077 - val_loss: 2.3354 - val_acc: 0.2022\n",
      "Epoch 88/100\n",
      "41092/41092 [==============================] - 82s 2ms/sample - loss: 2.3338 - acc: 0.2078 - val_loss: 2.3349 - val_acc: 0.2017\n",
      "Epoch 89/100\n",
      "41092/41092 [==============================] - 79s 2ms/sample - loss: 2.3335 - acc: 0.2085 - val_loss: 2.3352 - val_acc: 0.2017\n",
      "Epoch 90/100\n",
      "41092/41092 [==============================] - 82s 2ms/sample - loss: 2.3335 - acc: 0.2083 - val_loss: 2.3356 - val_acc: 0.2015\n",
      "Epoch 91/100\n",
      "41092/41092 [==============================] - 82s 2ms/sample - loss: 2.3334 - acc: 0.2079 - val_loss: 2.3345 - val_acc: 0.2031\n",
      "Epoch 92/100\n",
      "41092/41092 [==============================] - 80s 2ms/sample - loss: 2.3337 - acc: 0.2076 - val_loss: 2.3340 - val_acc: 0.2008\n",
      "Epoch 93/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3331 - acc: 0.2087 - val_loss: 2.3327 - val_acc: 0.2016\n",
      "Epoch 94/100\n",
      "41092/41092 [==============================] - 81s 2ms/sample - loss: 2.3316 - acc: 0.2081 - val_loss: 2.3303 - val_acc: 0.2078\n",
      "Epoch 95/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3268 - acc: 0.2075 - val_loss: 2.3342 - val_acc: 0.2013\n",
      "Epoch 96/100\n",
      "41092/41092 [==============================] - 82s 2ms/sample - loss: 2.3271 - acc: 0.2081 - val_loss: 2.3336 - val_acc: 0.1989\n",
      "Epoch 97/100\n",
      "41092/41092 [==============================] - 83s 2ms/sample - loss: 2.3222 - acc: 0.2084 - val_loss: 2.3288 - val_acc: 0.2088\n",
      "Epoch 98/100\n",
      "41092/41092 [==============================] - 79s 2ms/sample - loss: 2.3230 - acc: 0.2080 - val_loss: 2.3197 - val_acc: 0.2022\n",
      "Epoch 99/100\n",
      "41092/41092 [==============================] - 79s 2ms/sample - loss: 2.3197 - acc: 0.2080 - val_loss: 2.3196 - val_acc: 0.2013\n",
      "Epoch 100/100\n",
      "41092/41092 [==============================] - 78s 2ms/sample - loss: 2.3184 - acc: 0.2080 - val_loss: 2.3179 - val_acc: 0.2015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2429b70bb38>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 100, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 1024,\n",
    "         class_weight = class_weights,\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41092/41092 [==============================] - 10s 237us/sample\n",
      "[1605.2605 3342.3716 1870.072  2929.991  2956.8484 3397.54   1722.8541\n",
      " 1522.1451 6051.142  3470.4062 3480.356  8742.326 ]\n",
      "[1776. 3425. 1883. 3107. 2975. 3252. 1780. 1366. 6307. 3086. 3722. 8413.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x242aeaf6ac8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(train_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(train_labels, axis = 0))\n",
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(train_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10495/10495 [==============================] - 3s 243us/sample\n",
      "[ 412.40805  857.6437   476.03394  747.60516  753.32104  866.34796\n",
      "  442.5767   388.88046 1541.1246   882.3426   889.4471  2237.0215 ]\n",
      "[ 436.  781.  469.  833.  671.  862.  454.  316. 1849.  785.  936. 2103.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x242aebaf128>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))\n",
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"all\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 16)           2816      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 16)           64        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200, 32)           6272      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 200, 32)           128       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 35,148\n",
      "Trainable params: 32,076\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.pop()\n",
    "model.pop()\n",
    "model.pop()\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.add(LSTM(32, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = True,\n",
    "              dropout = .25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(64, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = False,\n",
    "              dropout = .25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    \"fit\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41092 samples, validate on 10495 samples\n",
      "Epoch 1/100\n",
      "41092/41092 [==============================] - 140s 3ms/sample - loss: 2.7514 - acc: 0.0848 - val_loss: 2.4763 - val_acc: 0.1535\n",
      "Epoch 2/100\n",
      "41092/41092 [==============================] - 137s 3ms/sample - loss: 2.5862 - acc: 0.0997 - val_loss: 2.4748 - val_acc: 0.1626\n",
      "Epoch 3/100\n",
      "41092/41092 [==============================] - 141s 3ms/sample - loss: 2.5341 - acc: 0.1050 - val_loss: 2.4724 - val_acc: 0.1641\n",
      "Epoch 4/100\n",
      "41092/41092 [==============================] - 145s 4ms/sample - loss: 2.5027 - acc: 0.1113 - val_loss: 2.4666 - val_acc: 0.1647\n",
      "Epoch 5/100\n",
      "41092/41092 [==============================] - 146s 4ms/sample - loss: 2.4845 - acc: 0.1152 - val_loss: 2.4564 - val_acc: 0.1650\n",
      "Epoch 6/100\n",
      "41092/41092 [==============================] - 148s 4ms/sample - loss: 2.4690 - acc: 0.1252 - val_loss: 2.4425 - val_acc: 0.1646\n",
      "Epoch 7/100\n",
      "41092/41092 [==============================] - 150s 4ms/sample - loss: 2.4572 - acc: 0.1292 - val_loss: 2.4318 - val_acc: 0.1589\n",
      "Epoch 8/100\n",
      "41092/41092 [==============================] - 155s 4ms/sample - loss: 2.4471 - acc: 0.1341 - val_loss: 2.4211 - val_acc: 0.1951\n",
      "Epoch 9/100\n",
      "41092/41092 [==============================] - 157s 4ms/sample - loss: 2.4394 - acc: 0.1429 - val_loss: 2.4106 - val_acc: 0.1968\n",
      "Epoch 10/100\n",
      "41092/41092 [==============================] - 161s 4ms/sample - loss: 2.4323 - acc: 0.1466 - val_loss: 2.4073 - val_acc: 0.1975\n",
      "Epoch 11/100\n",
      "41092/41092 [==============================] - 164s 4ms/sample - loss: 2.4264 - acc: 0.1527 - val_loss: 2.4078 - val_acc: 0.1990\n",
      "Epoch 12/100\n",
      "41092/41092 [==============================] - 168s 4ms/sample - loss: 2.4190 - acc: 0.1606 - val_loss: 2.4063 - val_acc: 0.1989\n",
      "Epoch 13/100\n",
      "41092/41092 [==============================] - 168s 4ms/sample - loss: 2.4126 - acc: 0.1662 - val_loss: 2.4006 - val_acc: 0.2001\n",
      "Epoch 14/100\n",
      "41092/41092 [==============================] - 169s 4ms/sample - loss: 2.4071 - acc: 0.1750 - val_loss: 2.3935 - val_acc: 0.1994\n",
      "Epoch 15/100\n",
      "41092/41092 [==============================] - 174s 4ms/sample - loss: 2.4023 - acc: 0.1794 - val_loss: 2.3894 - val_acc: 0.2000\n",
      "Epoch 16/100\n",
      "41092/41092 [==============================] - 178s 4ms/sample - loss: 2.3957 - acc: 0.1868 - val_loss: 2.3854 - val_acc: 0.1994\n",
      "Epoch 17/100\n",
      "41092/41092 [==============================] - 179s 4ms/sample - loss: 2.3909 - acc: 0.1923 - val_loss: 2.3804 - val_acc: 0.1995\n",
      "Epoch 18/100\n",
      "41092/41092 [==============================] - 182s 4ms/sample - loss: 2.3854 - acc: 0.1964 - val_loss: 2.3744 - val_acc: 0.1996\n",
      "Epoch 19/100\n",
      "41092/41092 [==============================] - 186s 5ms/sample - loss: 2.3813 - acc: 0.1983 - val_loss: 2.3711 - val_acc: 0.1996\n",
      "Epoch 20/100\n",
      "41092/41092 [==============================] - 185s 4ms/sample - loss: 2.3764 - acc: 0.1991 - val_loss: 2.3660 - val_acc: 0.2000\n",
      "Epoch 21/100\n",
      "41092/41092 [==============================] - 183s 4ms/sample - loss: 2.3721 - acc: 0.2024 - val_loss: 2.3629 - val_acc: 0.1996\n",
      "Epoch 22/100\n",
      "41092/41092 [==============================] - 187s 5ms/sample - loss: 2.3677 - acc: 0.2028 - val_loss: 2.3602 - val_acc: 0.1996\n",
      "Epoch 23/100\n",
      "41092/41092 [==============================] - 188s 5ms/sample - loss: 2.3649 - acc: 0.2032 - val_loss: 2.3541 - val_acc: 0.1999\n",
      "Epoch 24/100\n",
      "41092/41092 [==============================] - 187s 5ms/sample - loss: 2.3605 - acc: 0.2039 - val_loss: 2.3494 - val_acc: 0.1999\n",
      "Epoch 25/100\n",
      "41092/41092 [==============================] - 190s 5ms/sample - loss: 2.3582 - acc: 0.2041 - val_loss: 2.3475 - val_acc: 0.1999\n",
      "Epoch 26/100\n",
      "41092/41092 [==============================] - 208s 5ms/sample - loss: 2.3549 - acc: 0.2052 - val_loss: 2.3441 - val_acc: 0.2004\n",
      "Epoch 27/100\n",
      "41092/41092 [==============================] - 214s 5ms/sample - loss: 2.3501 - acc: 0.2046 - val_loss: 2.3405 - val_acc: 0.2007\n",
      "Epoch 28/100\n",
      "41092/41092 [==============================] - 199s 5ms/sample - loss: 2.3485 - acc: 0.2052 - val_loss: 2.3374 - val_acc: 0.2005\n",
      "Epoch 29/100\n",
      "41092/41092 [==============================] - 216s 5ms/sample - loss: 2.3463 - acc: 0.2052 - val_loss: 2.3357 - val_acc: 0.2005\n",
      "Epoch 30/100\n",
      "41092/41092 [==============================] - 215s 5ms/sample - loss: 2.3443 - acc: 0.2063 - val_loss: 2.3329 - val_acc: 0.2008\n",
      "Epoch 31/100\n",
      "41092/41092 [==============================] - 220s 5ms/sample - loss: 2.3417 - acc: 0.2055 - val_loss: 2.3309 - val_acc: 0.2005\n",
      "Epoch 32/100\n",
      "41092/41092 [==============================] - 207s 5ms/sample - loss: 2.3389 - acc: 0.2054 - val_loss: 2.3289 - val_acc: 0.2008\n",
      "Epoch 33/100\n",
      "41092/41092 [==============================] - 218s 5ms/sample - loss: 2.3389 - acc: 0.2057 - val_loss: 2.3274 - val_acc: 0.2005\n",
      "Epoch 34/100\n",
      "41092/41092 [==============================] - 222s 5ms/sample - loss: 2.3362 - acc: 0.2060 - val_loss: 2.3256 - val_acc: 0.2008\n",
      "Epoch 35/100\n",
      "41092/41092 [==============================] - 200s 5ms/sample - loss: 2.3353 - acc: 0.2055 - val_loss: 2.3242 - val_acc: 0.2007\n",
      "Epoch 36/100\n",
      "41092/41092 [==============================] - 205s 5ms/sample - loss: 2.3335 - acc: 0.2066 - val_loss: 2.3221 - val_acc: 0.2015\n",
      "Epoch 37/100\n",
      "41092/41092 [==============================] - 224s 5ms/sample - loss: 2.3325 - acc: 0.2057 - val_loss: 2.3211 - val_acc: 0.2013\n",
      "Epoch 38/100\n",
      "41092/41092 [==============================] - 209s 5ms/sample - loss: 2.3311 - acc: 0.2062 - val_loss: 2.3196 - val_acc: 0.2011\n",
      "Epoch 39/100\n",
      "41092/41092 [==============================] - 211s 5ms/sample - loss: 2.3303 - acc: 0.2060 - val_loss: 2.3187 - val_acc: 0.2012\n",
      "Epoch 40/100\n",
      "41092/41092 [==============================] - 212s 5ms/sample - loss: 2.3289 - acc: 0.2061 - val_loss: 2.3172 - val_acc: 0.2011\n",
      "Epoch 41/100\n",
      "41092/41092 [==============================] - 211s 5ms/sample - loss: 2.3284 - acc: 0.2061 - val_loss: 2.3163 - val_acc: 0.2011\n",
      "Epoch 42/100\n",
      "41092/41092 [==============================] - 221s 5ms/sample - loss: 2.3291 - acc: 0.2060 - val_loss: 2.3161 - val_acc: 0.2012\n",
      "Epoch 43/100\n",
      "41092/41092 [==============================] - 222s 5ms/sample - loss: 2.3276 - acc: 0.2063 - val_loss: 2.3153 - val_acc: 0.2010\n",
      "Epoch 44/100\n",
      "41092/41092 [==============================] - 223s 5ms/sample - loss: 2.3270 - acc: 0.2062 - val_loss: 2.3149 - val_acc: 0.2010\n",
      "Epoch 45/100\n",
      "41092/41092 [==============================] - 210s 5ms/sample - loss: 2.3267 - acc: 0.2065 - val_loss: 2.3143 - val_acc: 0.2009\n",
      "Epoch 46/100\n",
      "41092/41092 [==============================] - 222s 5ms/sample - loss: 2.3263 - acc: 0.2069 - val_loss: 2.3136 - val_acc: 0.2010\n",
      "Epoch 47/100\n",
      "41092/41092 [==============================] - 221s 5ms/sample - loss: 2.3249 - acc: 0.2062 - val_loss: 2.3120 - val_acc: 0.2011\n",
      "Epoch 48/100\n",
      "41092/41092 [==============================] - 218s 5ms/sample - loss: 2.3250 - acc: 0.2067 - val_loss: 2.3119 - val_acc: 0.2010\n",
      "Epoch 49/100\n",
      "41092/41092 [==============================] - 200s 5ms/sample - loss: 2.3253 - acc: 0.2067 - val_loss: 2.3120 - val_acc: 0.2012\n",
      "Epoch 50/100\n",
      "41092/41092 [==============================] - 220s 5ms/sample - loss: 2.3250 - acc: 0.2067 - val_loss: 2.3119 - val_acc: 0.2011\n",
      "Epoch 51/100\n",
      "41092/41092 [==============================] - 218s 5ms/sample - loss: 2.3245 - acc: 0.2072 - val_loss: 2.3115 - val_acc: 0.2013\n",
      "Epoch 52/100\n",
      "41092/41092 [==============================] - 218s 5ms/sample - loss: 2.3238 - acc: 0.2069 - val_loss: 2.3114 - val_acc: 0.2016\n",
      "Epoch 53/100\n",
      "41092/41092 [==============================] - 225s 5ms/sample - loss: 2.3246 - acc: 0.2068 - val_loss: 2.3107 - val_acc: 0.2015\n",
      "Epoch 54/100\n",
      "41092/41092 [==============================] - 218s 5ms/sample - loss: 2.3236 - acc: 0.2066 - val_loss: 2.3104 - val_acc: 0.2014\n",
      "Epoch 55/100\n",
      "41092/41092 [==============================] - 217s 5ms/sample - loss: 2.3234 - acc: 0.2070 - val_loss: 2.3106 - val_acc: 0.2015\n",
      "Epoch 56/100\n",
      "41092/41092 [==============================] - 223s 5ms/sample - loss: 2.3240 - acc: 0.2064 - val_loss: 2.3100 - val_acc: 0.2012\n",
      "Epoch 57/100\n",
      "41092/41092 [==============================] - 224s 5ms/sample - loss: 2.3224 - acc: 0.2069 - val_loss: 2.3103 - val_acc: 0.2012\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41092/41092 [==============================] - 223s 5ms/sample - loss: 2.3232 - acc: 0.2070 - val_loss: 2.3102 - val_acc: 0.2013\n",
      "Epoch 59/100\n",
      "41092/41092 [==============================] - 216s 5ms/sample - loss: 2.3226 - acc: 0.2071 - val_loss: 2.3103 - val_acc: 0.2014\n",
      "Epoch 60/100\n",
      "41092/41092 [==============================] - 220s 5ms/sample - loss: 2.3235 - acc: 0.2069 - val_loss: 2.3107 - val_acc: 0.2012\n",
      "Epoch 61/100\n",
      "41092/41092 [==============================] - 223s 5ms/sample - loss: 2.3230 - acc: 0.2069 - val_loss: 2.3104 - val_acc: 0.2015\n",
      "Epoch 62/100\n",
      "41092/41092 [==============================] - 216s 5ms/sample - loss: 2.3225 - acc: 0.2069 - val_loss: 2.3103 - val_acc: 0.2013\n",
      "Epoch 63/100\n",
      "41092/41092 [==============================] - 220s 5ms/sample - loss: 2.3230 - acc: 0.2071 - val_loss: 2.3100 - val_acc: 0.2015\n",
      "Epoch 64/100\n",
      "41092/41092 [==============================] - 223s 5ms/sample - loss: 2.3222 - acc: 0.2071 - val_loss: 2.3101 - val_acc: 0.2016\n",
      "Epoch 65/100\n",
      "41092/41092 [==============================] - 218s 5ms/sample - loss: 2.3222 - acc: 0.2069 - val_loss: 2.3103 - val_acc: 0.2013\n",
      "Epoch 66/100\n",
      "41092/41092 [==============================] - 223s 5ms/sample - loss: 2.3221 - acc: 0.2069 - val_loss: 2.3104 - val_acc: 0.2013\n",
      "Epoch 67/100\n",
      "41092/41092 [==============================] - 220s 5ms/sample - loss: 2.3224 - acc: 0.2066 - val_loss: 2.3098 - val_acc: 0.2016\n",
      "Epoch 68/100\n",
      "41092/41092 [==============================] - 210s 5ms/sample - loss: 2.3225 - acc: 0.2072 - val_loss: 2.3098 - val_acc: 0.2015\n",
      "Epoch 69/100\n",
      "41092/41092 [==============================] - 216s 5ms/sample - loss: 2.3214 - acc: 0.2069 - val_loss: 2.3097 - val_acc: 0.2015\n",
      "Epoch 70/100\n",
      "41092/41092 [==============================] - 205s 5ms/sample - loss: 2.3217 - acc: 0.2070 - val_loss: 2.3096 - val_acc: 0.2016\n",
      "Epoch 71/100\n",
      "41092/41092 [==============================] - 222s 5ms/sample - loss: 2.3221 - acc: 0.2070 - val_loss: 2.3097 - val_acc: 0.2013\n",
      "Epoch 72/100\n",
      "41092/41092 [==============================] - 226s 6ms/sample - loss: 2.3218 - acc: 0.2071 - val_loss: 2.3098 - val_acc: 0.2013\n",
      "Epoch 73/100\n",
      "41092/41092 [==============================] - 208s 5ms/sample - loss: 2.3215 - acc: 0.2076 - val_loss: 2.3097 - val_acc: 0.2014\n",
      "Epoch 74/100\n",
      "41092/41092 [==============================] - 217s 5ms/sample - loss: 2.3216 - acc: 0.2071 - val_loss: 2.3096 - val_acc: 0.2013\n",
      "Epoch 75/100\n",
      "41092/41092 [==============================] - 229s 6ms/sample - loss: 2.3212 - acc: 0.2070 - val_loss: 2.3098 - val_acc: 0.2012\n",
      "Epoch 76/100\n",
      "41092/41092 [==============================] - 234s 6ms/sample - loss: 2.3209 - acc: 0.2073 - val_loss: 2.3101 - val_acc: 0.2013\n",
      "Epoch 77/100\n",
      "41092/41092 [==============================] - 229s 6ms/sample - loss: 2.3216 - acc: 0.2069 - val_loss: 2.3099 - val_acc: 0.2011\n",
      "Epoch 78/100\n",
      "41092/41092 [==============================] - 230s 6ms/sample - loss: 2.3212 - acc: 0.2069 - val_loss: 2.3105 - val_acc: 0.2010\n",
      "Epoch 79/100\n",
      "41092/41092 [==============================] - 228s 6ms/sample - loss: 2.3208 - acc: 0.2076 - val_loss: 2.3102 - val_acc: 0.2009\n",
      "Epoch 80/100\n",
      "41092/41092 [==============================] - 228s 6ms/sample - loss: 2.3212 - acc: 0.2069 - val_loss: 2.3104 - val_acc: 0.2010\n",
      "Epoch 81/100\n",
      "41092/41092 [==============================] - 224s 5ms/sample - loss: 2.3205 - acc: 0.2072 - val_loss: 2.3102 - val_acc: 0.2010\n",
      "Epoch 82/100\n",
      "41092/41092 [==============================] - 222s 5ms/sample - loss: 2.3215 - acc: 0.2070 - val_loss: 2.3099 - val_acc: 0.2009\n",
      "Epoch 83/100\n",
      "41092/41092 [==============================] - 226s 6ms/sample - loss: 2.3212 - acc: 0.2072 - val_loss: 2.3102 - val_acc: 0.2008\n",
      "Epoch 84/100\n",
      "41092/41092 [==============================] - 229s 6ms/sample - loss: 2.3213 - acc: 0.2070 - val_loss: 2.3096 - val_acc: 0.2010\n",
      "Epoch 85/100\n",
      "41092/41092 [==============================] - 227s 6ms/sample - loss: 2.3212 - acc: 0.2072 - val_loss: 2.3096 - val_acc: 0.2011\n",
      "Epoch 86/100\n",
      "41092/41092 [==============================] - 221s 5ms/sample - loss: 2.3210 - acc: 0.2072 - val_loss: 2.3098 - val_acc: 0.2010\n",
      "Epoch 87/100\n",
      "41092/41092 [==============================] - 227s 6ms/sample - loss: 2.3208 - acc: 0.2074 - val_loss: 2.3098 - val_acc: 0.2010\n",
      "Epoch 88/100\n",
      "41092/41092 [==============================] - 226s 5ms/sample - loss: 2.3209 - acc: 0.2073 - val_loss: 2.3096 - val_acc: 0.2010\n",
      "Epoch 89/100\n",
      "41092/41092 [==============================] - 229s 6ms/sample - loss: 2.3207 - acc: 0.2071 - val_loss: 2.3098 - val_acc: 0.2011\n",
      "Epoch 90/100\n",
      "41092/41092 [==============================] - 230s 6ms/sample - loss: 2.3204 - acc: 0.2073 - val_loss: 2.3100 - val_acc: 0.2009\n",
      "Epoch 91/100\n",
      "41092/41092 [==============================] - 233s 6ms/sample - loss: 2.3211 - acc: 0.2077 - val_loss: 2.3099 - val_acc: 0.2010\n",
      "Epoch 92/100\n",
      "41092/41092 [==============================] - 234s 6ms/sample - loss: 2.3207 - acc: 0.2072 - val_loss: 2.3097 - val_acc: 0.2009\n",
      "Epoch 93/100\n",
      "41092/41092 [==============================] - 228s 6ms/sample - loss: 2.3197 - acc: 0.2072 - val_loss: 2.3099 - val_acc: 0.2009\n",
      "Epoch 94/100\n",
      "41092/41092 [==============================] - 226s 5ms/sample - loss: 2.3208 - acc: 0.2075 - val_loss: 2.3100 - val_acc: 0.2010\n",
      "Epoch 95/100\n",
      "41092/41092 [==============================] - 219s 5ms/sample - loss: 2.3200 - acc: 0.2072 - val_loss: 2.3106 - val_acc: 0.2009\n",
      "Epoch 96/100\n",
      "41092/41092 [==============================] - 223s 5ms/sample - loss: 2.3204 - acc: 0.2069 - val_loss: 2.3105 - val_acc: 0.2010\n",
      "Epoch 97/100\n",
      "41092/41092 [==============================] - 225s 5ms/sample - loss: 2.3203 - acc: 0.2075 - val_loss: 2.3103 - val_acc: 0.2010\n",
      "Epoch 98/100\n",
      "41092/41092 [==============================] - 223s 5ms/sample - loss: 2.3196 - acc: 0.2077 - val_loss: 2.3111 - val_acc: 0.2009\n",
      "Epoch 99/100\n",
      "41092/41092 [==============================] - 221s 5ms/sample - loss: 2.3202 - acc: 0.2069 - val_loss: 2.3099 - val_acc: 0.2009\n",
      "Epoch 100/100\n",
      "41092/41092 [==============================] - 223s 5ms/sample - loss: 2.3199 - acc: 0.2080 - val_loss: 2.3103 - val_acc: 0.2010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x242a36f3a90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 100, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 1024,\n",
    "         class_weight = class_weights,\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41092/41092 [==============================] - 29s 703us/sample\n",
      "[1779.7416 3361.408  1899.6012 3170.8997 2991.3484 3316.3118 1790.7776\n",
      " 1390.4574 6283.0386 3094.5225 3690.8193 8318.799 ]\n",
      "[1776. 3425. 1883. 3107. 2975. 3252. 1780. 1366. 6307. 3086. 3722. 8413.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x242af80a780>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(train_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(train_labels, axis = 0))\n",
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(train_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10495/10495 [==============================] - 7s 693us/sample\n",
      "[ 455.97357  860.18317  482.35217  811.49365  761.19635  846.054\n",
      "  458.1075   354.98557 1598.8673   786.79626  947.5248  2131.4912 ]\n",
      "[ 436.  781.  469.  833.  671.  862.  454.  316. 1849.  785.  936. 2103.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x242af86a748>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))\n",
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 16)           2816      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 16)           64        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200, 32)           6272      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 200, 32)           128       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               13000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                2412      \n",
      "=================================================================\n",
      "Total params: 50,580\n",
      "Trainable params: 40,772\n",
      "Non-trainable params: 9,808\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.pop()\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[4].trainable = True\n",
    "model.layers[5].trainable = True\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    \"fit\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41092 samples, validate on 10495 samples\n",
      "Epoch 1/100\n",
      "41092/41092 [==============================] - 239s 6ms/sample - loss: 3.1610 - acc: 0.0917 - val_loss: 2.5924 - val_acc: 0.0993\n",
      "Epoch 2/100\n",
      "41092/41092 [==============================] - 232s 6ms/sample - loss: 2.9468 - acc: 0.1055 - val_loss: 2.5222 - val_acc: 0.1021\n",
      "Epoch 3/100\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.8730 - acc: 0.1109 - val_loss: 2.4593 - val_acc: 0.1646\n",
      "Epoch 4/100\n",
      "41092/41092 [==============================] - 247s 6ms/sample - loss: 2.8023 - acc: 0.1172 - val_loss: 2.4226 - val_acc: 0.1681\n",
      "Epoch 5/100\n",
      "41092/41092 [==============================] - 250s 6ms/sample - loss: 2.7680 - acc: 0.1225 - val_loss: 2.3979 - val_acc: 0.1999\n",
      "Epoch 6/100\n",
      "41092/41092 [==============================] - 238s 6ms/sample - loss: 2.7180 - acc: 0.1326 - val_loss: 2.3812 - val_acc: 0.2000\n",
      "Epoch 7/100\n",
      "41092/41092 [==============================] - 238s 6ms/sample - loss: 2.6912 - acc: 0.1342 - val_loss: 2.3667 - val_acc: 0.2010\n",
      "Epoch 8/100\n",
      "41092/41092 [==============================] - 239s 6ms/sample - loss: 2.6624 - acc: 0.1404 - val_loss: 2.3575 - val_acc: 0.2004\n",
      "Epoch 9/100\n",
      "41092/41092 [==============================] - 238s 6ms/sample - loss: 2.6299 - acc: 0.1423 - val_loss: 2.3529 - val_acc: 0.2017\n",
      "Epoch 10/100\n",
      "41092/41092 [==============================] - 238s 6ms/sample - loss: 2.6152 - acc: 0.1486 - val_loss: 2.3484 - val_acc: 0.2022\n",
      "Epoch 11/100\n",
      "41092/41092 [==============================] - 238s 6ms/sample - loss: 2.5970 - acc: 0.1499 - val_loss: 2.3419 - val_acc: 0.2017\n",
      "Epoch 12/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.5844 - acc: 0.1543 - val_loss: 2.3423 - val_acc: 0.2023\n",
      "Epoch 13/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.5651 - acc: 0.1549 - val_loss: 2.3294 - val_acc: 0.2022\n",
      "Epoch 14/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.5525 - acc: 0.1544 - val_loss: 2.3268 - val_acc: 0.2018\n",
      "Epoch 15/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.5333 - acc: 0.1589 - val_loss: 2.3318 - val_acc: 0.2017\n",
      "Epoch 16/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.5279 - acc: 0.1616 - val_loss: 2.3252 - val_acc: 0.2014\n",
      "Epoch 17/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.5126 - acc: 0.1614 - val_loss: 2.3270 - val_acc: 0.2019\n",
      "Epoch 18/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.5064 - acc: 0.1644 - val_loss: 2.3257 - val_acc: 0.2022\n",
      "Epoch 19/100\n",
      "41092/41092 [==============================] - 240s 6ms/sample - loss: 2.4990 - acc: 0.1667 - val_loss: 2.3260 - val_acc: 0.2007\n",
      "Epoch 20/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.4821 - acc: 0.1707 - val_loss: 2.3277 - val_acc: 0.2025\n",
      "Epoch 21/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.4797 - acc: 0.1696 - val_loss: 2.3241 - val_acc: 0.2021\n",
      "Epoch 22/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.4707 - acc: 0.1753 - val_loss: 2.3224 - val_acc: 0.2018\n",
      "Epoch 23/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.4666 - acc: 0.1737 - val_loss: 2.3266 - val_acc: 0.2025\n",
      "Epoch 24/100\n",
      "41092/41092 [==============================] - 246s 6ms/sample - loss: 2.4538 - acc: 0.1768 - val_loss: 2.3300 - val_acc: 0.2026\n",
      "Epoch 25/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.4436 - acc: 0.1788 - val_loss: 2.3223 - val_acc: 0.2025\n",
      "Epoch 26/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.4459 - acc: 0.1782 - val_loss: 2.3214 - val_acc: 0.2027\n",
      "Epoch 27/100\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.4348 - acc: 0.1781 - val_loss: 2.3232 - val_acc: 0.2027\n",
      "Epoch 28/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.4328 - acc: 0.1800 - val_loss: 2.3202 - val_acc: 0.2027\n",
      "Epoch 29/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.4309 - acc: 0.1819 - val_loss: 2.3198 - val_acc: 0.2019\n",
      "Epoch 30/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.4258 - acc: 0.1841 - val_loss: 2.3192 - val_acc: 0.2020\n",
      "Epoch 31/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.4214 - acc: 0.1850 - val_loss: 2.3163 - val_acc: 0.2024\n",
      "Epoch 32/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.4143 - acc: 0.1845 - val_loss: 2.3162 - val_acc: 0.2027\n",
      "Epoch 33/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.4109 - acc: 0.1864 - val_loss: 2.3183 - val_acc: 0.2025\n",
      "Epoch 34/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.4079 - acc: 0.1877 - val_loss: 2.3186 - val_acc: 0.2023\n",
      "Epoch 35/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.4032 - acc: 0.1885 - val_loss: 2.3152 - val_acc: 0.2017\n",
      "Epoch 36/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.4009 - acc: 0.1886 - val_loss: 2.3165 - val_acc: 0.2023\n",
      "Epoch 37/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3990 - acc: 0.1908 - val_loss: 2.3153 - val_acc: 0.2023\n",
      "Epoch 38/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.3958 - acc: 0.1928 - val_loss: 2.3173 - val_acc: 0.2026\n",
      "Epoch 39/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3926 - acc: 0.1953 - val_loss: 2.3168 - val_acc: 0.2025\n",
      "Epoch 40/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3890 - acc: 0.1950 - val_loss: 2.3172 - val_acc: 0.2025\n",
      "Epoch 41/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3860 - acc: 0.1952 - val_loss: 2.3173 - val_acc: 0.2029\n",
      "Epoch 42/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3832 - acc: 0.1949 - val_loss: 2.3186 - val_acc: 0.2031\n",
      "Epoch 43/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.3849 - acc: 0.1961 - val_loss: 2.3187 - val_acc: 0.2030\n",
      "Epoch 44/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3795 - acc: 0.1960 - val_loss: 2.3184 - val_acc: 0.2030\n",
      "Epoch 45/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3810 - acc: 0.1990 - val_loss: 2.3155 - val_acc: 0.2026\n",
      "Epoch 46/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3782 - acc: 0.1959 - val_loss: 2.3155 - val_acc: 0.2029\n",
      "Epoch 47/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.3744 - acc: 0.1978 - val_loss: 2.3172 - val_acc: 0.2027\n",
      "Epoch 48/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3711 - acc: 0.1997 - val_loss: 2.3150 - val_acc: 0.2026\n",
      "Epoch 49/100\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.3727 - acc: 0.1992 - val_loss: 2.3147 - val_acc: 0.2025\n",
      "Epoch 50/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3684 - acc: 0.1983 - val_loss: 2.3151 - val_acc: 0.2024\n",
      "Epoch 51/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3689 - acc: 0.2010 - val_loss: 2.3165 - val_acc: 0.2017\n",
      "Epoch 52/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.3640 - acc: 0.2011 - val_loss: 2.3153 - val_acc: 0.2025\n",
      "Epoch 53/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3642 - acc: 0.1998 - val_loss: 2.3162 - val_acc: 0.2024\n",
      "Epoch 54/100\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.3623 - acc: 0.2015 - val_loss: 2.3150 - val_acc: 0.2028\n",
      "Epoch 55/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3617 - acc: 0.2008 - val_loss: 2.3150 - val_acc: 0.2027\n",
      "Epoch 56/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3623 - acc: 0.2022 - val_loss: 2.3159 - val_acc: 0.2024\n",
      "Epoch 57/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3593 - acc: 0.2033 - val_loss: 2.3144 - val_acc: 0.2025\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.3579 - acc: 0.2024 - val_loss: 2.3134 - val_acc: 0.2024\n",
      "Epoch 59/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3584 - acc: 0.2019 - val_loss: 2.3128 - val_acc: 0.2021\n",
      "Epoch 60/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3551 - acc: 0.2034 - val_loss: 2.3140 - val_acc: 0.2022\n",
      "Epoch 61/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3544 - acc: 0.2029 - val_loss: 2.3140 - val_acc: 0.2023\n",
      "Epoch 62/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3535 - acc: 0.2042 - val_loss: 2.3133 - val_acc: 0.2024\n",
      "Epoch 63/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3502 - acc: 0.2039 - val_loss: 2.3134 - val_acc: 0.2025\n",
      "Epoch 64/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3489 - acc: 0.2037 - val_loss: 2.3145 - val_acc: 0.2025\n",
      "Epoch 65/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.3491 - acc: 0.2051 - val_loss: 2.3132 - val_acc: 0.2022\n",
      "Epoch 66/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3479 - acc: 0.2034 - val_loss: 2.3137 - val_acc: 0.2026\n",
      "Epoch 67/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.3479 - acc: 0.2032 - val_loss: 2.3146 - val_acc: 0.2027\n",
      "Epoch 68/100\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.3486 - acc: 0.2021 - val_loss: 2.3145 - val_acc: 0.2026\n",
      "Epoch 69/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.3469 - acc: 0.2029 - val_loss: 2.3127 - val_acc: 0.2024\n",
      "Epoch 70/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.3435 - acc: 0.2041 - val_loss: 2.3131 - val_acc: 0.2026\n",
      "Epoch 71/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3452 - acc: 0.2029 - val_loss: 2.3132 - val_acc: 0.2026\n",
      "Epoch 72/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3443 - acc: 0.2042 - val_loss: 2.3135 - val_acc: 0.2027\n",
      "Epoch 73/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.3437 - acc: 0.2040 - val_loss: 2.3128 - val_acc: 0.2027\n",
      "Epoch 74/100\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.3415 - acc: 0.2050 - val_loss: 2.3130 - val_acc: 0.2028\n",
      "Epoch 75/100\n",
      "41092/41092 [==============================] - 246s 6ms/sample - loss: 2.3425 - acc: 0.2041 - val_loss: 2.3130 - val_acc: 0.2023\n",
      "Epoch 76/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.3428 - acc: 0.2050 - val_loss: 2.3130 - val_acc: 0.2023\n",
      "Epoch 77/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3430 - acc: 0.2041 - val_loss: 2.3126 - val_acc: 0.2025\n",
      "Epoch 78/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3400 - acc: 0.2039 - val_loss: 2.3119 - val_acc: 0.2027\n",
      "Epoch 79/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3383 - acc: 0.2049 - val_loss: 2.3132 - val_acc: 0.2027\n",
      "Epoch 80/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3396 - acc: 0.2037 - val_loss: 2.3127 - val_acc: 0.2024\n",
      "Epoch 81/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.3371 - acc: 0.2052 - val_loss: 2.3125 - val_acc: 0.2023\n",
      "Epoch 82/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3377 - acc: 0.2052 - val_loss: 2.3120 - val_acc: 0.2023\n",
      "Epoch 83/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3371 - acc: 0.2050 - val_loss: 2.3123 - val_acc: 0.2026\n",
      "Epoch 84/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3357 - acc: 0.2046 - val_loss: 2.3112 - val_acc: 0.2024\n",
      "Epoch 85/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3361 - acc: 0.2050 - val_loss: 2.3119 - val_acc: 0.2025\n",
      "Epoch 86/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3337 - acc: 0.2054 - val_loss: 2.3121 - val_acc: 0.2027\n",
      "Epoch 87/100\n",
      "41092/41092 [==============================] - 241s 6ms/sample - loss: 2.3366 - acc: 0.2048 - val_loss: 2.3119 - val_acc: 0.2024\n",
      "Epoch 88/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3364 - acc: 0.2051 - val_loss: 2.3129 - val_acc: 0.2024\n",
      "Epoch 89/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3358 - acc: 0.2058 - val_loss: 2.3123 - val_acc: 0.2021\n",
      "Epoch 90/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3361 - acc: 0.2050 - val_loss: 2.3123 - val_acc: 0.2024\n",
      "Epoch 91/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3335 - acc: 0.2049 - val_loss: 2.3123 - val_acc: 0.2024\n",
      "Epoch 92/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3339 - acc: 0.2047 - val_loss: 2.3123 - val_acc: 0.2022\n",
      "Epoch 93/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3337 - acc: 0.2056 - val_loss: 2.3118 - val_acc: 0.2024\n",
      "Epoch 94/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3323 - acc: 0.2055 - val_loss: 2.3120 - val_acc: 0.2023\n",
      "Epoch 95/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3328 - acc: 0.2053 - val_loss: 2.3113 - val_acc: 0.2021\n",
      "Epoch 96/100\n",
      "41092/41092 [==============================] - 242s 6ms/sample - loss: 2.3322 - acc: 0.2060 - val_loss: 2.3142 - val_acc: 0.2023\n",
      "Epoch 97/100\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.3329 - acc: 0.2049 - val_loss: 2.3115 - val_acc: 0.2021\n",
      "Epoch 98/100\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.3310 - acc: 0.2053 - val_loss: 2.3108 - val_acc: 0.2020\n",
      "Epoch 99/100\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.3323 - acc: 0.2057 - val_loss: 2.3118 - val_acc: 0.2021\n",
      "Epoch 100/100\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.3304 - acc: 0.2058 - val_loss: 2.3117 - val_acc: 0.2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x242a358f278>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 100, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 1024,\n",
    "         class_weight = class_weights,\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41092/41092 [==============================] - 34s 833us/sample\n",
      "[1780.1079 3459.8347 1854.2997 3169.9446 3022.2246 3272.3555 1837.0573\n",
      " 1351.1122 6214.4194 3070.714  3743.0315 8318.708 ]\n",
      "[1776. 3425. 1883. 3107. 2975. 3252. 1780. 1366. 6307. 3086. 3722. 8413.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x242aee25e48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(train_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(train_labels, axis = 0))\n",
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(train_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10495/10495 [==============================] - 8s 779us/sample\n",
      "[ 455.87842  885.6502   470.71295  810.90845  769.4802   833.90295\n",
      "  470.78192  344.679   1580.1887   781.0578   959.73785 2131.7124 ]\n",
      "[ 436.  781.  469.  833.  671.  862.  454.  316. 1849.  785.  936. 2103.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x242aeea0c50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))\n",
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    \"fit\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 16)           2816      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 16)           64        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200, 32)           6272      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 200, 32)           128       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               13000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                2412      \n",
      "=================================================================\n",
      "Total params: 91,580\n",
      "Trainable params: 90,556\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.pop()\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41092 samples, validate on 10495 samples\n",
      "Epoch 1/200\n",
      "41092/41092 [==============================] - 250s 6ms/sample - loss: 3.2436 - acc: 0.0927 - val_loss: 2.5660 - val_acc: 0.0899\n",
      "Epoch 2/200\n",
      "41092/41092 [==============================] - 244s 6ms/sample - loss: 2.8819 - acc: 0.1071 - val_loss: 2.4711 - val_acc: 0.1801\n",
      "Epoch 3/200\n",
      "41092/41092 [==============================] - 243s 6ms/sample - loss: 2.7482 - acc: 0.1245 - val_loss: 2.4263 - val_acc: 0.1830\n",
      "Epoch 4/200\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.6803 - acc: 0.1411 - val_loss: 2.4096 - val_acc: 0.2100\n",
      "Epoch 5/200\n",
      "41092/41092 [==============================] - 246s 6ms/sample - loss: 2.6346 - acc: 0.1490 - val_loss: 2.3896 - val_acc: 0.2015\n",
      "Epoch 6/200\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.6007 - acc: 0.1611 - val_loss: 2.3800 - val_acc: 0.2013\n",
      "Epoch 7/200\n",
      "41092/41092 [==============================] - 246s 6ms/sample - loss: 2.5790 - acc: 0.1663 - val_loss: 2.3676 - val_acc: 0.2079\n",
      "Epoch 8/200\n",
      "41092/41092 [==============================] - 245s 6ms/sample - loss: 2.5682 - acc: 0.1763 - val_loss: 2.3763 - val_acc: 0.2015\n",
      "Epoch 9/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.5434 - acc: 0.1836 - val_loss: 2.3711 - val_acc: 0.2017\n",
      "Epoch 10/200\n",
      "41092/41092 [==============================] - 246s 6ms/sample - loss: 2.5375 - acc: 0.1869 - val_loss: 2.3685 - val_acc: 0.2019\n",
      "Epoch 11/200\n",
      "41092/41092 [==============================] - 247s 6ms/sample - loss: 2.5246 - acc: 0.1887 - val_loss: 2.3682 - val_acc: 0.2019\n",
      "Epoch 12/200\n",
      "41092/41092 [==============================] - 247s 6ms/sample - loss: 2.5183 - acc: 0.1907 - val_loss: 2.3668 - val_acc: 0.2018\n",
      "Epoch 13/200\n",
      "41092/41092 [==============================] - 247s 6ms/sample - loss: 2.4983 - acc: 0.1921 - val_loss: 2.3630 - val_acc: 0.2018\n",
      "Epoch 14/200\n",
      "41092/41092 [==============================] - 247s 6ms/sample - loss: 2.4980 - acc: 0.1932 - val_loss: 2.3642 - val_acc: 0.2011\n",
      "Epoch 15/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4911 - acc: 0.1941 - val_loss: 2.3606 - val_acc: 0.2019\n",
      "Epoch 16/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4792 - acc: 0.1945 - val_loss: 2.3615 - val_acc: 0.2010\n",
      "Epoch 17/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4743 - acc: 0.1940 - val_loss: 2.3562 - val_acc: 0.2015\n",
      "Epoch 18/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.5097 - acc: 0.1946 - val_loss: 2.3641 - val_acc: 0.1804\n",
      "Epoch 19/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.5024 - acc: 0.1963 - val_loss: 2.3560 - val_acc: 0.2017\n",
      "Epoch 20/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4925 - acc: 0.1991 - val_loss: 2.3439 - val_acc: 0.2023\n",
      "Epoch 21/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4845 - acc: 0.2002 - val_loss: 2.3470 - val_acc: 0.2021\n",
      "Epoch 22/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4850 - acc: 0.2009 - val_loss: 2.3481 - val_acc: 0.2020\n",
      "Epoch 23/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4826 - acc: 0.2012 - val_loss: 2.3482 - val_acc: 0.2015\n",
      "Epoch 24/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4736 - acc: 0.2004 - val_loss: 2.3544 - val_acc: 0.2013\n",
      "Epoch 25/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4676 - acc: 0.2011 - val_loss: 2.3544 - val_acc: 0.2011\n",
      "Epoch 26/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4657 - acc: 0.2020 - val_loss: 2.3552 - val_acc: 0.2012\n",
      "Epoch 27/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4598 - acc: 0.2021 - val_loss: 2.3548 - val_acc: 0.2010\n",
      "Epoch 28/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4655 - acc: 0.2023 - val_loss: 2.3550 - val_acc: 0.2018\n",
      "Epoch 29/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4573 - acc: 0.2022 - val_loss: 2.3556 - val_acc: 0.2016\n",
      "Epoch 30/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4536 - acc: 0.2020 - val_loss: 2.3542 - val_acc: 0.2013\n",
      "Epoch 31/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4541 - acc: 0.2014 - val_loss: 2.3537 - val_acc: 0.2014\n",
      "Epoch 32/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4465 - acc: 0.2024 - val_loss: 2.3531 - val_acc: 0.2010\n",
      "Epoch 33/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4519 - acc: 0.2024 - val_loss: 2.3531 - val_acc: 0.2013\n",
      "Epoch 34/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4411 - acc: 0.2032 - val_loss: 2.3540 - val_acc: 0.2012\n",
      "Epoch 35/200\n",
      "41092/41092 [==============================] - 250s 6ms/sample - loss: 2.4396 - acc: 0.2025 - val_loss: 2.3542 - val_acc: 0.2009\n",
      "Epoch 36/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4310 - acc: 0.2023 - val_loss: 2.3526 - val_acc: 0.2011\n",
      "Epoch 37/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4381 - acc: 0.2023 - val_loss: 2.3542 - val_acc: 0.2009\n",
      "Epoch 38/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4365 - acc: 0.2027 - val_loss: 2.3525 - val_acc: 0.2010\n",
      "Epoch 39/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4248 - acc: 0.2024 - val_loss: 2.3530 - val_acc: 0.2008\n",
      "Epoch 40/200\n",
      "41092/41092 [==============================] - 247s 6ms/sample - loss: 2.4234 - acc: 0.2019 - val_loss: 2.3550 - val_acc: 0.2008\n",
      "Epoch 41/200\n",
      "41092/41092 [==============================] - 247s 6ms/sample - loss: 2.4313 - acc: 0.2034 - val_loss: 2.3505 - val_acc: 0.2010\n",
      "Epoch 42/200\n",
      "41092/41092 [==============================] - 247s 6ms/sample - loss: 2.4205 - acc: 0.2030 - val_loss: 2.3503 - val_acc: 0.2010\n",
      "Epoch 43/200\n",
      "41092/41092 [==============================] - 247s 6ms/sample - loss: 2.4279 - acc: 0.2028 - val_loss: 2.3519 - val_acc: 0.2007\n",
      "Epoch 44/200\n",
      "41092/41092 [==============================] - 250s 6ms/sample - loss: 2.4249 - acc: 0.2029 - val_loss: 2.3565 - val_acc: 0.2006\n",
      "Epoch 45/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4194 - acc: 0.2036 - val_loss: 2.3517 - val_acc: 0.2006\n",
      "Epoch 46/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4202 - acc: 0.2032 - val_loss: 2.3505 - val_acc: 0.2004\n",
      "Epoch 47/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4219 - acc: 0.2033 - val_loss: 2.3503 - val_acc: 0.2008\n",
      "Epoch 48/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4163 - acc: 0.2030 - val_loss: 2.3505 - val_acc: 0.2006\n",
      "Epoch 49/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4122 - acc: 0.2028 - val_loss: 2.3508 - val_acc: 0.2006\n",
      "Epoch 50/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4111 - acc: 0.2041 - val_loss: 2.3509 - val_acc: 0.2001\n",
      "Epoch 51/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4114 - acc: 0.2036 - val_loss: 2.3478 - val_acc: 0.2000\n",
      "Epoch 52/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4044 - acc: 0.2037 - val_loss: 2.3494 - val_acc: 0.2002\n",
      "Epoch 53/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4061 - acc: 0.2036 - val_loss: 2.3483 - val_acc: 0.1998\n",
      "Epoch 54/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4092 - acc: 0.2037 - val_loss: 2.3483 - val_acc: 0.2003\n",
      "Epoch 55/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4082 - acc: 0.2030 - val_loss: 2.3454 - val_acc: 0.2001\n",
      "Epoch 56/200\n",
      "41092/41092 [==============================] - 249s 6ms/sample - loss: 2.4009 - acc: 0.2037 - val_loss: 2.3494 - val_acc: 0.2000\n",
      "Epoch 57/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4060 - acc: 0.2039 - val_loss: 2.3474 - val_acc: 0.2005\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4117 - acc: 0.2040 - val_loss: 2.3571 - val_acc: 0.2003\n",
      "Epoch 59/200\n",
      "41092/41092 [==============================] - 248s 6ms/sample - loss: 2.4052 - acc: 0.2037 - val_loss: 2.3455 - val_acc: 0.2003\n",
      "Epoch 60/200\n",
      "41092/41092 [==============================] - 255s 6ms/sample - loss: 2.4007 - acc: 0.2042 - val_loss: 2.3434 - val_acc: 0.2000\n",
      "Epoch 61/200\n",
      "41092/41092 [==============================] - 253s 6ms/sample - loss: 2.3995 - acc: 0.2044 - val_loss: 2.3425 - val_acc: 0.2002\n",
      "Epoch 62/200\n",
      "41092/41092 [==============================] - 262s 6ms/sample - loss: 2.4065 - acc: 0.2036 - val_loss: 2.3427 - val_acc: 0.2008\n",
      "Epoch 63/200\n",
      "24576/41092 [================>.............] - ETA: 1:44 - loss: 2.3992 - acc: 0.2041"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 200, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 1024,\n",
    "         class_weight = class_weights,\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
