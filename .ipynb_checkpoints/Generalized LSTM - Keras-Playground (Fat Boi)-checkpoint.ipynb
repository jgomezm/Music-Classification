{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, LSTM, Flatten, BatchNormalization\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "#import keras as keras\n",
    "#from keras import Sequential\n",
    "#from keras.layers import LSTM, Dense, LSTM, Flatten\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgomezm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "enc = pickle.load( open( \"pickle\\\\enc.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.92811562, 0.99980535, 1.81855196, 1.10213496, 1.15103641,\n",
       "       1.05299303, 1.92378277, 2.5068326 , 0.5429417 , 1.10963491,\n",
       "       0.92002508, 0.4070288 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x = pickle.load( open( \"pickle\\\\val_x.p\", \"rb\" ) )\n",
    "train_x = pickle.load( open( \"pickle\\\\train_x.p\", \"rb\" ) )\n",
    "val_labels = pickle.load( open( \"pickle\\\\val_labels.p\", \"rb\" ) )\n",
    "train_labels = pickle.load( open( \"pickle\\\\train_labels.p\", \"rb\" ) )\n",
    "class_weights = pickle.load( open( \"pickle\\\\class_weights.p\", \"rb\" ) )\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41092, 200, 27)\n",
      "41092\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41092, 200, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41092, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1776., 3425., 1883., 3107., 2975., 3252., 1780., 1366., 6307.,\n",
       "       3086., 3722., 8413.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 436.,  781.,  469.,  833.,  671.,  862.,  454.,  316., 1849.,\n",
       "        785.,  936., 2103.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(val_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2047357149810182"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.sum(train_labels, axis = 0))/sum(np.sum(train_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.200381133873273"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.sum(val_labels, axis = 0))/sum(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AU', 'CO', 'EC', 'GB', 'HK', 'JP', 'MX', 'NZ', 'TN', 'TR', 'US',\n",
       "       'ZA'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_index = 2\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(64, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(128, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(256, \n",
    "               input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "               return_sequences = False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 64)           23552     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 64)           256       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200, 128)          98816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200, 128)          512       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 521,484\n",
      "Trainable params: 520,588\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41092 samples, validate on 10495 samples\n",
      "Epoch 1/100\n",
      "41092/41092 [==============================] - 429s 10ms/sample - loss: 2.5916 - acc: 0.1420\n",
      "Epoch 2/100\n",
      "41092/41092 [==============================] - 519s 13ms/sample - loss: 2.4628 - acc: 0.1739\n",
      "Epoch 3/100\n",
      "41092/41092 [==============================] - 538s 13ms/sample - loss: 2.4276 - acc: 0.1813\n",
      "Epoch 4/100\n",
      "41092/41092 [==============================] - 549s 13ms/sample - loss: 2.4018 - acc: 0.1899\n",
      "Epoch 5/100\n",
      "41092/41092 [==============================] - 574s 14ms/sample - loss: 2.3804 - acc: 0.1982 - val_loss: 2.4066 - val_acc: 0.1675\n",
      "Epoch 6/100\n",
      "41092/41092 [==============================] - 515s 13ms/sample - loss: 2.3628 - acc: 0.2009\n",
      "Epoch 7/100\n",
      "41092/41092 [==============================] - 525s 13ms/sample - loss: 2.3484 - acc: 0.2058\n",
      "Epoch 8/100\n",
      "41092/41092 [==============================] - 526s 13ms/sample - loss: 2.3396 - acc: 0.2078\n",
      "Epoch 9/100\n",
      "41092/41092 [==============================] - 530s 13ms/sample - loss: 2.3293 - acc: 0.2097\n",
      "Epoch 10/100\n",
      "41092/41092 [==============================] - 561s 14ms/sample - loss: 2.3236 - acc: 0.2118 - val_loss: 2.3490 - val_acc: 0.1994\n",
      "Epoch 11/100\n",
      "41092/41092 [==============================] - 544s 13ms/sample - loss: 2.3179 - acc: 0.2125\n",
      "Epoch 12/100\n",
      "41092/41092 [==============================] - 543s 13ms/sample - loss: 2.3105 - acc: 0.2146\n",
      "Epoch 13/100\n",
      "41092/41092 [==============================] - 563s 14ms/sample - loss: 2.3079 - acc: 0.2146\n",
      "Epoch 14/100\n",
      "41092/41092 [==============================] - 558s 14ms/sample - loss: 2.3028 - acc: 0.2147\n",
      "Epoch 15/100\n",
      "41092/41092 [==============================] - 581s 14ms/sample - loss: 2.3003 - acc: 0.2179 - val_loss: 2.3405 - val_acc: 0.2072\n",
      "Epoch 16/100\n",
      "41092/41092 [==============================] - 554s 13ms/sample - loss: 2.2971 - acc: 0.2158\n",
      "Epoch 17/100\n",
      "41092/41092 [==============================] - 560s 14ms/sample - loss: 2.2959 - acc: 0.2189\n",
      "Epoch 18/100\n",
      "41092/41092 [==============================] - 569s 14ms/sample - loss: 2.2941 - acc: 0.2168\n",
      "Epoch 19/100\n",
      "41092/41092 [==============================] - 565s 14ms/sample - loss: 2.2912 - acc: 0.2185\n",
      "Epoch 20/100\n",
      "41092/41092 [==============================] - 606s 15ms/sample - loss: 2.2896 - acc: 0.2188 - val_loss: 2.3343 - val_acc: 0.2160\n",
      "Epoch 21/100\n",
      "41092/41092 [==============================] - 579s 14ms/sample - loss: 2.2883 - acc: 0.2187\n",
      "Epoch 22/100\n",
      "41092/41092 [==============================] - 575s 14ms/sample - loss: 2.2845 - acc: 0.2206\n",
      "Epoch 23/100\n",
      "41092/41092 [==============================] - 575s 14ms/sample - loss: 2.2835 - acc: 0.2224\n",
      "Epoch 24/100\n",
      "41092/41092 [==============================] - 577s 14ms/sample - loss: 2.2825 - acc: 0.2218\n",
      "Epoch 25/100\n",
      "41092/41092 [==============================] - 605s 15ms/sample - loss: 2.2827 - acc: 0.2209 - val_loss: 2.3452 - val_acc: 0.2136\n",
      "Epoch 26/100\n",
      "41092/41092 [==============================] - 587s 14ms/sample - loss: 2.2790 - acc: 0.2224\n",
      "Epoch 27/100\n",
      "41092/41092 [==============================] - 590s 14ms/sample - loss: 2.2756 - acc: 0.2231\n",
      "Epoch 28/100\n",
      "41092/41092 [==============================] - 589s 14ms/sample - loss: 2.2754 - acc: 0.2248\n",
      "Epoch 29/100\n",
      "41092/41092 [==============================] - 594s 14ms/sample - loss: 2.2742 - acc: 0.2258\n",
      "Epoch 30/100\n",
      "41092/41092 [==============================] - 615s 15ms/sample - loss: 2.2757 - acc: 0.2247 - val_loss: 2.3480 - val_acc: 0.2010\n",
      "Epoch 31/100\n",
      "41092/41092 [==============================] - 596s 14ms/sample - loss: 2.2703 - acc: 0.2242\n",
      "Epoch 32/100\n",
      "41092/41092 [==============================] - 595s 14ms/sample - loss: 2.2703 - acc: 0.2249\n",
      "Epoch 33/100\n",
      "41092/41092 [==============================] - 585s 14ms/sample - loss: 2.2663 - acc: 0.2282\n",
      "Epoch 34/100\n",
      "41092/41092 [==============================] - 587s 14ms/sample - loss: 2.2671 - acc: 0.2282\n",
      "Epoch 35/100\n",
      "41092/41092 [==============================] - 612s 15ms/sample - loss: 2.2660 - acc: 0.2320 - val_loss: 2.3355 - val_acc: 0.2131\n",
      "Epoch 36/100\n",
      "41092/41092 [==============================] - 592s 14ms/sample - loss: 2.2621 - acc: 0.2373\n",
      "Epoch 37/100\n",
      "41092/41092 [==============================] - 591s 14ms/sample - loss: 2.2637 - acc: 0.2344\n",
      "Epoch 38/100\n",
      "41092/41092 [==============================] - 591s 14ms/sample - loss: 2.2552 - acc: 0.2418\n",
      "Epoch 39/100\n",
      "41092/41092 [==============================] - 592s 14ms/sample - loss: 2.2508 - acc: 0.2422\n",
      "Epoch 40/100\n",
      "41092/41092 [==============================] - 618s 15ms/sample - loss: 2.2465 - acc: 0.2464 - val_loss: 2.3189 - val_acc: 0.2233\n",
      "Epoch 41/100\n",
      "41092/41092 [==============================] - 599s 15ms/sample - loss: 2.2454 - acc: 0.2458\n",
      "Epoch 42/100\n",
      "41092/41092 [==============================] - 603s 15ms/sample - loss: 2.2420 - acc: 0.2463\n",
      "Epoch 43/100\n",
      "41092/41092 [==============================] - 598s 15ms/sample - loss: 2.2420 - acc: 0.2460\n",
      "Epoch 44/100\n",
      "41092/41092 [==============================] - 600s 15ms/sample - loss: 2.2406 - acc: 0.2449\n",
      "Epoch 45/100\n",
      "41092/41092 [==============================] - 621s 15ms/sample - loss: 2.2356 - acc: 0.2486 - val_loss: 2.3090 - val_acc: 0.2337\n",
      "Epoch 46/100\n",
      "41092/41092 [==============================] - 601s 15ms/sample - loss: 2.2326 - acc: 0.2493\n",
      "Epoch 47/100\n",
      "41092/41092 [==============================] - 599s 15ms/sample - loss: 2.2280 - acc: 0.2507\n",
      "Epoch 48/100\n",
      "41092/41092 [==============================] - 602s 15ms/sample - loss: 2.2284 - acc: 0.2498\n",
      "Epoch 49/100\n",
      "41092/41092 [==============================] - 601s 15ms/sample - loss: 2.2215 - acc: 0.2532\n",
      "Epoch 50/100\n",
      "41092/41092 [==============================] - 622s 15ms/sample - loss: 2.2200 - acc: 0.2545 - val_loss: 2.2998 - val_acc: 0.2432\n",
      "Epoch 51/100\n",
      "41092/41092 [==============================] - 598s 15ms/sample - loss: 2.2209 - acc: 0.2549\n",
      "Epoch 52/100\n",
      "41092/41092 [==============================] - 601s 15ms/sample - loss: 2.2157 - acc: 0.2561\n",
      "Epoch 53/100\n",
      "41092/41092 [==============================] - 605s 15ms/sample - loss: 2.2136 - acc: 0.2562\n",
      "Epoch 54/100\n",
      "41092/41092 [==============================] - 600s 15ms/sample - loss: 2.2149 - acc: 0.2564\n",
      "Epoch 55/100\n",
      "41092/41092 [==============================] - 627s 15ms/sample - loss: 2.2136 - acc: 0.2560 - val_loss: 2.3059 - val_acc: 0.2317\n",
      "Epoch 56/100\n",
      "41092/41092 [==============================] - 608s 15ms/sample - loss: 2.2148 - acc: 0.2547\n",
      "Epoch 57/100\n",
      "41092/41092 [==============================] - 605s 15ms/sample - loss: 2.2098 - acc: 0.2553\n",
      "Epoch 58/100\n",
      "41092/41092 [==============================] - 606s 15ms/sample - loss: 2.2060 - acc: 0.2579\n",
      "Epoch 59/100\n",
      "41092/41092 [==============================] - 603s 15ms/sample - loss: 2.2032 - acc: 0.2586\n",
      "Epoch 60/100\n",
      "41092/41092 [==============================] - 627s 15ms/sample - loss: 2.2044 - acc: 0.2578 - val_loss: 2.2830 - val_acc: 0.2454\n",
      "Epoch 61/100\n",
      "41092/41092 [==============================] - 606s 15ms/sample - loss: 2.2034 - acc: 0.2575\n",
      "Epoch 62/100\n",
      "41092/41092 [==============================] - 606s 15ms/sample - loss: 2.2045 - acc: 0.2576\n",
      "Epoch 63/100\n",
      "41092/41092 [==============================] - 606s 15ms/sample - loss: 2.2019 - acc: 0.2570\n",
      "Epoch 64/100\n",
      "41092/41092 [==============================] - 607s 15ms/sample - loss: 2.1964 - acc: 0.2581\n",
      "Epoch 65/100\n",
      "41092/41092 [==============================] - 631s 15ms/sample - loss: 2.1965 - acc: 0.2584 - val_loss: 2.3001 - val_acc: 0.2421\n",
      "Epoch 66/100\n",
      "41092/41092 [==============================] - 615s 15ms/sample - loss: 2.1945 - acc: 0.2574\n",
      "Epoch 67/100\n",
      "41092/41092 [==============================] - 613s 15ms/sample - loss: 2.1936 - acc: 0.2592\n",
      "Epoch 68/100\n",
      "41092/41092 [==============================] - 611s 15ms/sample - loss: 2.1944 - acc: 0.2590\n",
      "Epoch 69/100\n",
      "41092/41092 [==============================] - 614s 15ms/sample - loss: 2.1929 - acc: 0.2602\n",
      "Epoch 70/100\n",
      "41092/41092 [==============================] - 639s 16ms/sample - loss: 2.1946 - acc: 0.2601 - val_loss: 2.3029 - val_acc: 0.2386\n",
      "Epoch 71/100\n",
      "41092/41092 [==============================] - 614s 15ms/sample - loss: 2.1993 - acc: 0.2573\n",
      "Epoch 72/100\n",
      "41092/41092 [==============================] - 614s 15ms/sample - loss: 2.1918 - acc: 0.2609\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41092/41092 [==============================] - 613s 15ms/sample - loss: 2.1859 - acc: 0.2618\n",
      "Epoch 74/100\n",
      "41092/41092 [==============================] - 610s 15ms/sample - loss: 2.1889 - acc: 0.2622\n",
      "Epoch 75/100\n",
      "41092/41092 [==============================] - 633s 15ms/sample - loss: 2.1900 - acc: 0.2621 - val_loss: 2.2753 - val_acc: 0.2468\n",
      "Epoch 76/100\n",
      "41092/41092 [==============================] - 612s 15ms/sample - loss: 2.1869 - acc: 0.2620\n",
      "Epoch 77/100\n",
      "41092/41092 [==============================] - 613s 15ms/sample - loss: 2.1868 - acc: 0.2634\n",
      "Epoch 78/100\n",
      "41092/41092 [==============================] - 611s 15ms/sample - loss: 2.1837 - acc: 0.2638\n",
      "Epoch 79/100\n",
      "41092/41092 [==============================] - 614s 15ms/sample - loss: 2.1816 - acc: 0.2615\n",
      "Epoch 80/100\n",
      "41092/41092 [==============================] - 640s 16ms/sample - loss: 2.1846 - acc: 0.2616 - val_loss: 2.2958 - val_acc: 0.2421\n",
      "Epoch 81/100\n",
      "41092/41092 [==============================] - 614s 15ms/sample - loss: 2.1805 - acc: 0.2626\n",
      "Epoch 82/100\n",
      "41092/41092 [==============================] - 613s 15ms/sample - loss: 2.1796 - acc: 0.2619\n",
      "Epoch 83/100\n",
      "41092/41092 [==============================] - 615s 15ms/sample - loss: 2.1785 - acc: 0.2645\n",
      "Epoch 84/100\n",
      "41092/41092 [==============================] - 617s 15ms/sample - loss: 2.1749 - acc: 0.2663\n",
      "Epoch 85/100\n",
      "41092/41092 [==============================] - 640s 16ms/sample - loss: 2.1750 - acc: 0.2662 - val_loss: 2.2891 - val_acc: 0.2434\n",
      "Epoch 86/100\n",
      "41092/41092 [==============================] - 617s 15ms/sample - loss: 2.1729 - acc: 0.2656\n",
      "Epoch 87/100\n",
      "41092/41092 [==============================] - 615s 15ms/sample - loss: 2.1735 - acc: 0.2657\n",
      "Epoch 88/100\n",
      "41092/41092 [==============================] - 616s 15ms/sample - loss: 2.1751 - acc: 0.2637\n",
      "Epoch 89/100\n",
      "41092/41092 [==============================] - 617s 15ms/sample - loss: 2.1711 - acc: 0.2655\n",
      "Epoch 90/100\n",
      "41092/41092 [==============================] - 643s 16ms/sample - loss: 2.1731 - acc: 0.2655 - val_loss: 2.3023 - val_acc: 0.2287\n",
      "Epoch 91/100\n",
      "41092/41092 [==============================] - 620s 15ms/sample - loss: 2.1668 - acc: 0.2685\n",
      "Epoch 92/100\n",
      "41092/41092 [==============================] - 621s 15ms/sample - loss: 2.1675 - acc: 0.2666\n",
      "Epoch 93/100\n",
      "41092/41092 [==============================] - 621s 15ms/sample - loss: 2.1649 - acc: 0.2674\n",
      "Epoch 94/100\n",
      "41092/41092 [==============================] - 620s 15ms/sample - loss: 2.1623 - acc: 0.2674\n",
      "Epoch 95/100\n",
      "41092/41092 [==============================] - 643s 16ms/sample - loss: 2.1625 - acc: 0.2689 - val_loss: 2.2860 - val_acc: 0.2397\n",
      "Epoch 96/100\n",
      "41092/41092 [==============================] - 619s 15ms/sample - loss: 2.1604 - acc: 0.2692\n",
      "Epoch 97/100\n",
      "41092/41092 [==============================] - 620s 15ms/sample - loss: 2.1604 - acc: 0.2692\n",
      "Epoch 98/100\n",
      "41092/41092 [==============================] - 620s 15ms/sample - loss: 2.1606 - acc: 0.2694\n",
      "Epoch 99/100\n",
      "41092/41092 [==============================] - 623s 15ms/sample - loss: 2.1594 - acc: 0.2703\n",
      "Epoch 100/100\n",
      "41092/41092 [==============================] - 648s 16ms/sample - loss: 2.1562 - acc: 0.2707 - val_loss: 2.2814 - val_acc: 0.2404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25a13fc75c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 100, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          validation_freq = 5,\n",
    "          batch_size = 512,\n",
    "         class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10495/10495 [==============================] - 26s 2ms/sample\n",
      "[ 433.61353  834.7048   470.83618  733.3042   803.9827   727.3774\n",
      "  430.8839   326.6934  1766.83     803.48914  947.16785 2216.1138 ]\n",
      "[ 436.  781.  469.  833.  671.  862.  454.  316. 1849.  785.  936. 2103.]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25a13adf5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 LSTM w/ Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 64)           23552     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 64)           256       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200, 128)          98816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200, 128)          512       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               51400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                2412      \n",
      "=================================================================\n",
      "Total params: 573,012\n",
      "Trainable params: 448,964\n",
      "Non-trainable params: 124,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.pop()\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[-1].trainable = True\n",
    "model.layers[-2].trainable = True\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41092 samples, validate on 10495 samples\n",
      "Epoch 1/100\n",
      "41092/41092 [==============================] - 580s 14ms/sample - loss: 2.4548 - acc: 0.1925\n",
      "Epoch 2/100\n",
      "41092/41092 [==============================] - 580s 14ms/sample - loss: 2.2609 - acc: 0.2370\n",
      "Epoch 3/100\n",
      "41092/41092 [==============================] - 579s 14ms/sample - loss: 2.2170 - acc: 0.2499\n",
      "Epoch 4/100\n",
      "41092/41092 [==============================] - 580s 14ms/sample - loss: 2.1943 - acc: 0.2606\n",
      "Epoch 5/100\n",
      "41092/41092 [==============================] - 601s 15ms/sample - loss: 2.1813 - acc: 0.2633 - val_loss: 2.2709 - val_acc: 0.2401\n",
      "Epoch 6/100\n",
      "41092/41092 [==============================] - 562s 14ms/sample - loss: 2.1703 - acc: 0.2672\n",
      "Epoch 7/100\n",
      "41092/41092 [==============================] - 561s 14ms/sample - loss: 2.1624 - acc: 0.2703\n",
      "Epoch 8/100\n",
      "41092/41092 [==============================] - 569s 14ms/sample - loss: 2.1562 - acc: 0.2701\n",
      "Epoch 9/100\n",
      "41092/41092 [==============================] - 565s 14ms/sample - loss: 2.1529 - acc: 0.2722\n",
      "Epoch 10/100\n",
      "41092/41092 [==============================] - 587s 14ms/sample - loss: 2.1480 - acc: 0.2733 - val_loss: 2.2848 - val_acc: 0.2415\n",
      "Epoch 11/100\n",
      "41092/41092 [==============================] - 566s 14ms/sample - loss: 2.1453 - acc: 0.2746\n",
      "Epoch 12/100\n",
      "41092/41092 [==============================] - 566s 14ms/sample - loss: 2.1428 - acc: 0.2750\n",
      "Epoch 13/100\n",
      "41092/41092 [==============================] - 567s 14ms/sample - loss: 2.1388 - acc: 0.2769\n",
      "Epoch 14/100\n",
      "41092/41092 [==============================] - 565s 14ms/sample - loss: 2.1352 - acc: 0.2783\n",
      "Epoch 15/100\n",
      "41092/41092 [==============================] - 591s 14ms/sample - loss: 2.1308 - acc: 0.2797 - val_loss: 2.2871 - val_acc: 0.2422\n",
      "Epoch 16/100\n",
      "41092/41092 [==============================] - 567s 14ms/sample - loss: 2.1293 - acc: 0.2812\n",
      "Epoch 17/100\n",
      "41092/41092 [==============================] - 569s 14ms/sample - loss: 2.1272 - acc: 0.2811\n",
      "Epoch 18/100\n",
      "41092/41092 [==============================] - 570s 14ms/sample - loss: 2.1238 - acc: 0.2805\n",
      "Epoch 19/100\n",
      "41092/41092 [==============================] - 571s 14ms/sample - loss: 2.1222 - acc: 0.2817\n",
      "Epoch 20/100\n",
      "41092/41092 [==============================] - 593s 14ms/sample - loss: 2.1187 - acc: 0.2834 - val_loss: 2.2925 - val_acc: 0.2355\n",
      "Epoch 21/100\n",
      "41092/41092 [==============================] - 572s 14ms/sample - loss: 2.1192 - acc: 0.2830\n",
      "Epoch 22/100\n",
      "41092/41092 [==============================] - 573s 14ms/sample - loss: 2.1163 - acc: 0.2845\n",
      "Epoch 23/100\n",
      "41092/41092 [==============================] - 574s 14ms/sample - loss: 2.1117 - acc: 0.2854\n",
      "Epoch 24/100\n",
      "41092/41092 [==============================] - 575s 14ms/sample - loss: 2.1096 - acc: 0.2874\n",
      "Epoch 25/100\n",
      "41092/41092 [==============================] - 599s 15ms/sample - loss: 2.1101 - acc: 0.2868 - val_loss: 2.2968 - val_acc: 0.2392\n",
      "Epoch 26/100\n",
      "41092/41092 [==============================] - 576s 14ms/sample - loss: 2.1057 - acc: 0.2886\n",
      "Epoch 27/100\n",
      "41092/41092 [==============================] - 575s 14ms/sample - loss: 2.1042 - acc: 0.2888\n",
      "Epoch 28/100\n",
      "41092/41092 [==============================] - 576s 14ms/sample - loss: 2.1020 - acc: 0.2897\n",
      "Epoch 29/100\n",
      "41092/41092 [==============================] - 577s 14ms/sample - loss: 2.0980 - acc: 0.2916\n",
      "Epoch 30/100\n",
      "41092/41092 [==============================] - 598s 15ms/sample - loss: 2.0966 - acc: 0.2890 - val_loss: 2.3103 - val_acc: 0.2389\n",
      "Epoch 31/100\n",
      "41092/41092 [==============================] - 574s 14ms/sample - loss: 2.0938 - acc: 0.2906\n",
      "Epoch 32/100\n",
      "41092/41092 [==============================] - 574s 14ms/sample - loss: 2.0936 - acc: 0.2907\n",
      "Epoch 33/100\n",
      "41092/41092 [==============================] - 576s 14ms/sample - loss: 2.0896 - acc: 0.2930\n",
      "Epoch 34/100\n",
      "41092/41092 [==============================] - 579s 14ms/sample - loss: 2.0869 - acc: 0.2934\n",
      "Epoch 35/100\n",
      "41092/41092 [==============================] - 600s 15ms/sample - loss: 2.0838 - acc: 0.2956 - val_loss: 2.3140 - val_acc: 0.2350\n",
      "Epoch 36/100\n",
      "41092/41092 [==============================] - 579s 14ms/sample - loss: 2.0815 - acc: 0.2948\n",
      "Epoch 37/100\n",
      "41092/41092 [==============================] - 576s 14ms/sample - loss: 2.0792 - acc: 0.2966\n",
      "Epoch 38/100\n",
      "41092/41092 [==============================] - 579s 14ms/sample - loss: 2.0760 - acc: 0.2956\n",
      "Epoch 39/100\n",
      "41092/41092 [==============================] - 577s 14ms/sample - loss: 2.0748 - acc: 0.2967\n",
      "Epoch 40/100\n",
      "41092/41092 [==============================] - 605s 15ms/sample - loss: 2.0720 - acc: 0.2989 - val_loss: 2.3287 - val_acc: 0.2369\n",
      "Epoch 41/100\n",
      "41092/41092 [==============================] - 580s 14ms/sample - loss: 2.0695 - acc: 0.3001\n",
      "Epoch 42/100\n",
      "41092/41092 [==============================] - 578s 14ms/sample - loss: 2.0681 - acc: 0.2981\n",
      "Epoch 43/100\n",
      "41092/41092 [==============================] - 581s 14ms/sample - loss: 2.0639 - acc: 0.3028\n",
      "Epoch 44/100\n",
      "41092/41092 [==============================] - 581s 14ms/sample - loss: 2.0623 - acc: 0.2995\n",
      "Epoch 45/100\n",
      "41092/41092 [==============================] - 602s 15ms/sample - loss: 2.0609 - acc: 0.3034 - val_loss: 2.3297 - val_acc: 0.2366\n",
      "Epoch 46/100\n",
      "41092/41092 [==============================] - 578s 14ms/sample - loss: 2.0554 - acc: 0.3056\n",
      "Epoch 47/100\n",
      "41092/41092 [==============================] - 582s 14ms/sample - loss: 2.0549 - acc: 0.3025\n",
      "Epoch 48/100\n",
      "41092/41092 [==============================] - 582s 14ms/sample - loss: 2.0495 - acc: 0.3084\n",
      "Epoch 49/100\n",
      "41092/41092 [==============================] - 584s 14ms/sample - loss: 2.0484 - acc: 0.3057\n",
      "Epoch 50/100\n",
      "41092/41092 [==============================] - 607s 15ms/sample - loss: 2.0448 - acc: 0.3081 - val_loss: 2.3321 - val_acc: 0.2360\n",
      "Epoch 51/100\n",
      "41092/41092 [==============================] - 586s 14ms/sample - loss: 2.0423 - acc: 0.3102\n",
      "Epoch 52/100\n",
      "41092/41092 [==============================] - 584s 14ms/sample - loss: 2.0394 - acc: 0.3098\n",
      "Epoch 53/100\n",
      "41092/41092 [==============================] - 591s 14ms/sample - loss: 2.0363 - acc: 0.3123\n",
      "Epoch 54/100\n",
      "41092/41092 [==============================] - 588s 14ms/sample - loss: 2.0309 - acc: 0.3139\n",
      "Epoch 55/100\n",
      "41092/41092 [==============================] - 612s 15ms/sample - loss: 2.0312 - acc: 0.3122 - val_loss: 2.3591 - val_acc: 0.2315\n",
      "Epoch 56/100\n",
      "18432/41092 [============>.................] - ETA: 5:22 - loss: 2.0237 - acc: 0.3126"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-cae5fed08813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[0mvalidation_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m           class_weight=class_weights)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 50, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 512,\n",
    "          validation_freq = 5,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41092/41092 [==============================] - 100s 2ms/sample\n",
      "[1707.8851 3231.087  1822.9423 3403.6536 2695.7776 3357.2695 1820.3076\n",
      " 1267.0542 6413.303  3071.742  3931.343  8369.573 ]\n",
      "[1776. 3425. 1883. 3107. 2975. 3252. 1780. 1366. 6307. 3086. 3722. 8413.]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(train_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(train_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25a13ea99e8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(train_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10495/10495 [==============================] - 27s 3ms/sample\n",
      "[ 433.2286   833.2634   475.2657   855.3134   659.7776   837.32697\n",
      "  460.91257  314.58475 1721.3918   781.0865   993.13617 2129.7126 ]\n",
      "[ 436.  781.  469.  833.  671.  862.  454.  316. 1849.  785.  936. 2103.]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25a13df3c88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 64)           23552     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 64)           256       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200, 128)          98816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200, 128)          512       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               51400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                2412      \n",
      "=================================================================\n",
      "Total params: 573,012\n",
      "Trainable params: 448,964\n",
      "Non-trainable params: 124,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.pop()\n",
    "model.add(keras.layers.Dropout(.25))\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41092 samples, validate on 10495 samples\n",
      "Epoch 1/50\n",
      "41092/41092 [==============================] - 559s 14ms/sample - loss: 2.7229 - acc: 0.1448\n",
      "Epoch 2/50\n",
      "41092/41092 [==============================] - 558s 14ms/sample - loss: 2.4730 - acc: 0.1876\n",
      "Epoch 3/50\n",
      "41092/41092 [==============================] - 563s 14ms/sample - loss: 2.3978 - acc: 0.2041\n",
      "Epoch 4/50\n",
      "41092/41092 [==============================] - 563s 14ms/sample - loss: 2.3571 - acc: 0.2174\n",
      "Epoch 5/50\n",
      "41092/41092 [==============================] - 591s 14ms/sample - loss: 2.3266 - acc: 0.2255 - val_loss: 2.2914 - val_acc: 0.2394\n",
      "Epoch 6/50\n",
      "41092/41092 [==============================] - 560s 14ms/sample - loss: 2.3008 - acc: 0.2312\n",
      "Epoch 7/50\n",
      "41092/41092 [==============================] - 561s 14ms/sample - loss: 2.2887 - acc: 0.2360\n",
      "Epoch 8/50\n",
      "41092/41092 [==============================] - 558s 14ms/sample - loss: 2.2696 - acc: 0.2432\n",
      "Epoch 9/50\n",
      "41092/41092 [==============================] - 558s 14ms/sample - loss: 2.2496 - acc: 0.2460\n",
      "Epoch 10/50\n",
      "41092/41092 [==============================] - 580s 14ms/sample - loss: 2.2425 - acc: 0.2460 - val_loss: 2.2975 - val_acc: 0.2408\n",
      "Epoch 11/50\n",
      "41092/41092 [==============================] - 558s 14ms/sample - loss: 2.2290 - acc: 0.2519\n",
      "Epoch 12/50\n",
      "41092/41092 [==============================] - 562s 14ms/sample - loss: 2.2204 - acc: 0.2527\n",
      "Epoch 13/50\n",
      "41092/41092 [==============================] - 564s 14ms/sample - loss: 2.2078 - acc: 0.2579\n",
      "Epoch 14/50\n",
      "41092/41092 [==============================] - 565s 14ms/sample - loss: 2.1985 - acc: 0.2598\n",
      "Epoch 15/50\n",
      "41092/41092 [==============================] - 587s 14ms/sample - loss: 2.1905 - acc: 0.2643 - val_loss: 2.3129 - val_acc: 0.2407\n",
      "Epoch 16/50\n",
      "41092/41092 [==============================] - 560s 14ms/sample - loss: 2.1860 - acc: 0.2626\n",
      "Epoch 17/50\n",
      "41092/41092 [==============================] - 561s 14ms/sample - loss: 2.1748 - acc: 0.2660\n",
      "Epoch 18/50\n",
      "41092/41092 [==============================] - 561s 14ms/sample - loss: 2.1648 - acc: 0.2697\n",
      "Epoch 19/50\n",
      "41092/41092 [==============================] - 562s 14ms/sample - loss: 2.1641 - acc: 0.2689\n",
      "Epoch 20/50\n",
      "41092/41092 [==============================] - 585s 14ms/sample - loss: 2.1560 - acc: 0.2717 - val_loss: 2.3268 - val_acc: 0.2416\n",
      "Epoch 21/50\n",
      "41092/41092 [==============================] - 567s 14ms/sample - loss: 2.1542 - acc: 0.2713\n",
      "Epoch 22/50\n",
      "41092/41092 [==============================] - 570s 14ms/sample - loss: 2.1487 - acc: 0.2756\n",
      "Epoch 23/50\n",
      "41092/41092 [==============================] - 571s 14ms/sample - loss: 2.1373 - acc: 0.2790\n",
      "Epoch 24/50\n",
      "41092/41092 [==============================] - 568s 14ms/sample - loss: 2.1357 - acc: 0.2767\n",
      "Epoch 25/50\n",
      "41092/41092 [==============================] - 591s 14ms/sample - loss: 2.1300 - acc: 0.2801 - val_loss: 2.3343 - val_acc: 0.2335\n",
      "Epoch 26/50\n",
      "41092/41092 [==============================] - 564s 14ms/sample - loss: 2.1261 - acc: 0.2818\n",
      "Epoch 27/50\n",
      "41092/41092 [==============================] - 568s 14ms/sample - loss: 2.1186 - acc: 0.2842\n",
      "Epoch 28/50\n",
      "41092/41092 [==============================] - 570s 14ms/sample - loss: 2.1125 - acc: 0.2850\n",
      "Epoch 29/50\n",
      "41092/41092 [==============================] - 572s 14ms/sample - loss: 2.1089 - acc: 0.2865\n",
      "Epoch 30/50\n",
      "41092/41092 [==============================] - 597s 15ms/sample - loss: 2.1022 - acc: 0.2894 - val_loss: 2.3405 - val_acc: 0.2366\n",
      "Epoch 31/50\n",
      "41092/41092 [==============================] - 572s 14ms/sample - loss: 2.1044 - acc: 0.2874\n",
      "Epoch 32/50\n",
      "41092/41092 [==============================] - 571s 14ms/sample - loss: 2.0978 - acc: 0.2894\n",
      "Epoch 33/50\n",
      "41092/41092 [==============================] - 570s 14ms/sample - loss: 2.0914 - acc: 0.2930\n",
      "Epoch 34/50\n",
      "41092/41092 [==============================] - 569s 14ms/sample - loss: 2.0894 - acc: 0.2928\n",
      "Epoch 35/50\n",
      "41092/41092 [==============================] - 593s 14ms/sample - loss: 2.0842 - acc: 0.2945 - val_loss: 2.3597 - val_acc: 0.2330\n",
      "Epoch 36/50\n",
      "41092/41092 [==============================] - 567s 14ms/sample - loss: 2.0790 - acc: 0.2991\n",
      "Epoch 37/50\n",
      "41092/41092 [==============================] - 571s 14ms/sample - loss: 2.0746 - acc: 0.2963\n",
      "Epoch 38/50\n",
      "41092/41092 [==============================] - 571s 14ms/sample - loss: 2.0717 - acc: 0.2968\n",
      "Epoch 39/50\n",
      "41092/41092 [==============================] - 573s 14ms/sample - loss: 2.0640 - acc: 0.2994\n",
      "Epoch 40/50\n",
      "41092/41092 [==============================] - 599s 15ms/sample - loss: 2.0624 - acc: 0.3022 - val_loss: 2.3720 - val_acc: 0.2296\n",
      "Epoch 41/50\n",
      "33792/41092 [=======================>......] - ETA: 1:41 - loss: 2.0580 - acc: 0.3051"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-e240cf940926>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[0mvalidation_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m           class_weight=class_weights)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 50, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 512,\n",
    "          validation_freq = 5,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 64)           23552     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200, 64)           256       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200, 128)          98816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200, 128)          512       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               51400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                2412      \n",
      "=================================================================\n",
      "Total params: 614,012\n",
      "Trainable params: 94,924\n",
      "Non-trainable params: 519,088\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.pop()\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[-3].trainable = True\n",
    "model.layers[-4].trainable = True\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(keras.layers.Dropout(.25))\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41092 samples, validate on 10495 samples\n",
      "Epoch 1/100\n",
      "41092/41092 [==============================] - 588s 14ms/sample - loss: 2.6418 - acc: 0.1780\n",
      "Epoch 2/100\n",
      "41092/41092 [==============================] - 588s 14ms/sample - loss: 2.3326 - acc: 0.2338\n",
      "Epoch 3/100\n",
      "41092/41092 [==============================] - 588s 14ms/sample - loss: 2.2538 - acc: 0.2517\n",
      "Epoch 4/100\n",
      "41092/41092 [==============================] - 586s 14ms/sample - loss: 2.2149 - acc: 0.2617\n",
      "Epoch 5/100\n",
      "41092/41092 [==============================] - 613s 15ms/sample - loss: 2.1859 - acc: 0.2704 - val_loss: 2.4424 - val_acc: 0.2388\n",
      "Epoch 6/100\n",
      "41092/41092 [==============================] - 594s 14ms/sample - loss: 2.1639 - acc: 0.2736\n",
      "Epoch 7/100\n",
      "41092/41092 [==============================] - 600s 15ms/sample - loss: 2.1562 - acc: 0.2797\n",
      "Epoch 8/100\n",
      "41092/41092 [==============================] - 602s 15ms/sample - loss: 2.1400 - acc: 0.2806\n",
      "Epoch 9/100\n",
      "41092/41092 [==============================] - 601s 15ms/sample - loss: 2.1334 - acc: 0.2838\n",
      "Epoch 10/100\n",
      "41092/41092 [==============================] - 624s 15ms/sample - loss: 2.1199 - acc: 0.2885 - val_loss: 2.4531 - val_acc: 0.2359\n",
      "Epoch 11/100\n",
      "10240/41092 [======>.......................] - ETA: 7:29 - loss: 2.1190 - acc: 0.2820"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-cae5fed08813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[0mvalidation_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m           class_weight=class_weights)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 100, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 512,\n",
    "          validation_freq = 5,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41092/41092 [==============================] - 154s 4ms/sample\n",
      "[1842.3624 3415.8232 1948.7039 3182.664  3048.2583 3090.7764 1861.7598\n",
      " 1522.3951 6178.5957 3008.3567 3561.7456 8430.548 ]\n",
      "[1776. 3425. 1883. 3107. 2975. 3252. 1780. 1366. 6307. 3086. 3722. 8413.]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(train_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(train_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25a1c494860>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(train_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10495/10495 [==============================] - 53s 5ms/sample\n",
      "[ 467.8218   885.6304   505.4753   807.57434  738.2301   789.33484\n",
      "  472.97833  377.3737  1671.7861   750.09814  890.2638  2138.4155 ]\n",
      "[ 436.  781.  469.  833.  671.  862.  454.  316. 1849.  785.  936. 2103.]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25a1c552cc0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune full network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.pop()\n",
    "model.add(keras.layers.Dropout(.25))\n",
    "model.add(Dense(len(enc.categories_[0]), activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= adam, metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 100, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 256,\n",
    "          validation_freq = 5,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 100, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 256,\n",
    "          validation_freq = 5,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_labels,\n",
    "          epochs = 100, \n",
    "          shuffle = True,\n",
    "          validation_data = (val_x, val_labels),\n",
    "          batch_size = 256,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(val_x, batch_size = 256, verbose = 1)\n",
    "print(np.sum(preds, axis = 0))\n",
    "print(np.sum(val_labels, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        enc.inverse_transform(preds), \n",
    "        enc.inverse_transform(val_labels), \n",
    "        normalize = \"true\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
