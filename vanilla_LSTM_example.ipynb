{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234) ### DOES NOT WORK???\n",
    "w_length = 100\n",
    "n_countries = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = pd.DataFrame()\n",
    "us = pd.DataFrame()\n",
    "for file in glob.glob(\"Raw Track Data\\\\*.csv\"):\n",
    "    name = file[15:-4]\n",
    "    new = pd.read_csv(file)\n",
    "    if name[:2] == \"MX\":\n",
    "        mx = mx.append(new)\n",
    "    if name[:2] == \"US\":\n",
    "        us = us.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = mx.drop([\"confidence\", \"loudness_start\", \"loudness_max_time\", \"loudness_max\"], axis = 1)\n",
    "us = us.drop([\"confidence\", \"loudness_start\", \"loudness_max_time\", \"loudness_max\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2057082, 27)\n",
      "(1183336, 27)\n"
     ]
    }
   ],
   "source": [
    "print(mx.shape)\n",
    "mx = mx.drop_duplicates([\"track_id\", \"start\"])\n",
    "print(mx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294236, 27)\n",
      "(1272411, 27)\n"
     ]
    }
   ],
   "source": [
    "print(us.shape)\n",
    "us = us.drop_duplicates([\"track_id\", \"start\"])\n",
    "print(us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MX (1183336, 27)\n",
      "US (1272411, 27)\n"
     ]
    }
   ],
   "source": [
    "print(\"MX\", mx.shape)\n",
    "print(\"US\", us.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the playlists have common songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42593"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(us.track_id.isin(mx.track_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MX (1140743, 27)\n",
      "US (1229818, 27)\n"
     ]
    }
   ],
   "source": [
    "dupes = us[\"track_id\"].loc[us.track_id.isin(mx.track_id)]\n",
    "mx = mx.loc[~(mx[\"track_id\"].isin(dupes))]\n",
    "us = us.loc[~(us[\"track_id\"].isin(dupes))]\n",
    "print(\"MX\", mx.shape)\n",
    "print(\"US\", us.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input array for US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos = list(us.track_id.index[us.track_id.shift(1) != us.track_id]) # indices where the song changes\n",
    "new_pos.append(max(us.track_id.index) + 1) # add a new index to know where the last song ends\n",
    "split_pos = []\n",
    "for i in range(len(new_pos)-1):\n",
    "    split_pos = split_pos + list(range(new_pos[i], new_pos[i+1], w_length))\n",
    "split_pos = split_pos[1:]\n",
    "us_train = np.split(us.iloc[:,:27].to_numpy(), split_pos)\n",
    "# drop the short sequences\n",
    "short_seqs = []\n",
    "temp = [] \n",
    "for i, value in enumerate(us_train):\n",
    "    if value.shape[0] == w_length:\n",
    "        temp.append(value)\n",
    "us_train = temp\n",
    "us_train = np.stack(us_train)\n",
    "val_index = np.isin(us_train[:,:,26],\n",
    "                    np.random.choice(us.track_id.unique(), np.int(len(us.track_id.unique())/10)))\n",
    "val_index = val_index.sum(1) != 0\n",
    "us_val = us_train[val_index,:,:25] # drop track id\n",
    "us_train = us_train[np.logical_not(val_index),:,:25] # drop track id\n",
    "us_train = us_train.astype(\"float64\")\n",
    "us_val = us_val.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want songs to have the same number of observations, we can determine which element in the list returned by np.slit corresponds to which song (using new_pos) and randomly overpopulate accordingly. An alternative is to do this with an online batching if we have memory problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input array for MX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos = list(mx.track_id.index[mx.track_id.shift(1) != mx.track_id]) # indices where the song changes\n",
    "new_pos.append(max(mx.track_id.index) + 1) # add a new index to know where the last song ends\n",
    "split_pos = []\n",
    "for i in range(len(new_pos)-1):\n",
    "    split_pos = split_pos + list(range(new_pos[i], new_pos[i+1], w_length))\n",
    "split_pos = split_pos[1:]\n",
    "mx_train = np.split(mx.iloc[:,:27].to_numpy(), split_pos)\n",
    "# drop the short sequences\n",
    "short_seqs = []\n",
    "temp = [] \n",
    "for i, value in enumerate(mx_train):\n",
    "    if value.shape[0] == w_length:\n",
    "        temp.append(value)\n",
    "mx_train = temp\n",
    "mx_train = np.stack(mx_train)\n",
    "val_index = np.isin(mx_train[:,:,26],\n",
    "                    np.random.choice(mx.track_id.unique(), np.int(len(mx.track_id.unique())/10)))\n",
    "val_index = val_index.sum(1) != 0\n",
    "mx_val = mx_train[val_index,:,:25] # drop track id\n",
    "mx_train = mx_train[np.logical_not(val_index),:,:25] # drop track id\n",
    "mx_train = mx_train.astype(\"float64\")\n",
    "mx_val = mx_val.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Output arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22925, 100, 25) \n",
      " (3124, 100, 25) \n",
      " (22925, 2) \n",
      " (3124, 2)\n",
      "float64 \n",
      " float64 \n",
      " float32 \n",
      " float32\n"
     ]
    }
   ],
   "source": [
    "train_input = np.concatenate([us_train, mx_train])\n",
    "val_input = np.concatenate([us_val, mx_val])\n",
    "\n",
    "train_output = np.ones((us_train.shape[0], 1))\n",
    "train_output = np.concatenate([train_output, np.zeros((mx_train.shape[0], 1))])\n",
    "train_output = keras.utils.to_categorical(train_output)\n",
    "val_output = np.ones((us_val.shape[0], 1))\n",
    "val_output = np.concatenate([val_output, np.zeros((mx_val.shape[0], 1))])\n",
    "val_output = keras.utils.to_categorical(val_output)\n",
    "\n",
    "\n",
    "print(train_input.shape, \"\\n\", val_input.shape, \"\\n\", train_output.shape, \"\\n\", val_output.shape)\n",
    "print(train_input.dtype, \"\\n\", val_input.dtype, \"\\n\", train_output.dtype, \"\\n\", val_output.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 5,152\n",
      "Trainable params: 5,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "out_index = 2\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(25, input_shape=(w_length, train_input.shape[2]), dropout = .5, recurrent_dropout = .5))\n",
    "model.add(Dense(n_countries, activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= \"adam\", metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_input)\n",
    "train_input.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22925 samples, validate on 3124 samples\n",
      "Epoch 1/50\n",
      "22925/22925 [==============================] - 13s 563us/sample - loss: 0.7239 - acc: 0.5104 - val_loss: 0.6608 - val_acc: 0.6316\n",
      "Epoch 2/50\n",
      "22925/22925 [==============================] - 9s 385us/sample - loss: 0.6843 - acc: 0.5624 - val_loss: 0.6174 - val_acc: 0.7164\n",
      "Epoch 3/50\n",
      "22925/22925 [==============================] - 9s 372us/sample - loss: 0.6730 - acc: 0.5812 - val_loss: 0.5813 - val_acc: 0.7388\n",
      "Epoch 4/50\n",
      "22925/22925 [==============================] - 9s 404us/sample - loss: 0.6565 - acc: 0.6087 - val_loss: 0.5415 - val_acc: 0.7506\n",
      "Epoch 5/50\n",
      "22925/22925 [==============================] - 9s 386us/sample - loss: 0.6508 - acc: 0.6225 - val_loss: 0.5328 - val_acc: 0.7625\n",
      "Epoch 6/50\n",
      "22925/22925 [==============================] - 10s 436us/sample - loss: 0.6486 - acc: 0.6232 - val_loss: 0.4858 - val_acc: 0.8153\n",
      "Epoch 7/50\n",
      "22925/22925 [==============================] - 10s 434us/sample - loss: 0.6412 - acc: 0.6335 - val_loss: 0.4826 - val_acc: 0.8089\n",
      "Epoch 8/50\n",
      "22925/22925 [==============================] - 10s 416us/sample - loss: 0.6330 - acc: 0.6444 - val_loss: 0.4657 - val_acc: 0.8115\n",
      "Epoch 9/50\n",
      "22925/22925 [==============================] - 9s 397us/sample - loss: 0.6288 - acc: 0.6497 - val_loss: 0.4491 - val_acc: 0.8214\n",
      "Epoch 10/50\n",
      "22925/22925 [==============================] - 9s 403us/sample - loss: 0.6227 - acc: 0.6563 - val_loss: 0.4407 - val_acc: 0.8284\n",
      "Epoch 11/50\n",
      "22925/22925 [==============================] - 9s 391us/sample - loss: 0.6244 - acc: 0.6533 - val_loss: 0.4411 - val_acc: 0.8342\n",
      "Epoch 12/50\n",
      "22925/22925 [==============================] - 10s 451us/sample - loss: 0.6177 - acc: 0.6620 - val_loss: 0.4240 - val_acc: 0.8438\n",
      "Epoch 13/50\n",
      "22925/22925 [==============================] - 12s 516us/sample - loss: 0.6124 - acc: 0.6665 - val_loss: 0.4251 - val_acc: 0.8399\n",
      "Epoch 14/50\n",
      "22925/22925 [==============================] - 10s 444us/sample - loss: 0.6061 - acc: 0.6730 - val_loss: 0.4102 - val_acc: 0.8544\n",
      "Epoch 15/50\n",
      "22925/22925 [==============================] - 13s 556us/sample - loss: 0.6011 - acc: 0.6774 - val_loss: 0.4119 - val_acc: 0.8435\n",
      "Epoch 16/50\n",
      "22925/22925 [==============================] - 10s 445us/sample - loss: 0.6001 - acc: 0.6763 - val_loss: 0.4208 - val_acc: 0.8332\n",
      "Epoch 17/50\n",
      "22925/22925 [==============================] - 9s 386us/sample - loss: 0.5982 - acc: 0.6757 - val_loss: 0.4027 - val_acc: 0.8454\n",
      "Epoch 18/50\n",
      "22925/22925 [==============================] - 9s 401us/sample - loss: 0.6007 - acc: 0.6773 - val_loss: 0.4054 - val_acc: 0.8489\n",
      "Epoch 19/50\n",
      "22925/22925 [==============================] - 9s 393us/sample - loss: 0.5880 - acc: 0.6875 - val_loss: 0.4022 - val_acc: 0.8428\n",
      "Epoch 20/50\n",
      "22925/22925 [==============================] - 9s 388us/sample - loss: 0.5847 - acc: 0.6913 - val_loss: 0.3797 - val_acc: 0.8582\n",
      "Epoch 21/50\n",
      "22925/22925 [==============================] - 9s 373us/sample - loss: 0.5838 - acc: 0.6915 - val_loss: 0.3823 - val_acc: 0.8473\n",
      "Epoch 22/50\n",
      "22925/22925 [==============================] - 9s 385us/sample - loss: 0.5804 - acc: 0.6957 - val_loss: 0.3808 - val_acc: 0.8560\n",
      "Epoch 23/50\n",
      "22925/22925 [==============================] - 9s 407us/sample - loss: 0.5791 - acc: 0.6958 - val_loss: 0.3597 - val_acc: 0.8640\n",
      "Epoch 24/50\n",
      "22925/22925 [==============================] - 10s 433us/sample - loss: 0.5740 - acc: 0.7002 - val_loss: 0.3683 - val_acc: 0.8521\n",
      "Epoch 25/50\n",
      "22925/22925 [==============================] - 9s 399us/sample - loss: 0.5671 - acc: 0.7074 - val_loss: 0.3614 - val_acc: 0.8576\n",
      "Epoch 26/50\n",
      "22925/22925 [==============================] - 8s 370us/sample - loss: 0.5699 - acc: 0.7044 - val_loss: 0.3627 - val_acc: 0.8560\n",
      "Epoch 27/50\n",
      "22925/22925 [==============================] - 9s 384us/sample - loss: 0.5647 - acc: 0.7105 - val_loss: 0.3588 - val_acc: 0.8601\n",
      "Epoch 28/50\n",
      "22925/22925 [==============================] - 9s 379us/sample - loss: 0.5630 - acc: 0.7145 - val_loss: 0.3673 - val_acc: 0.8553\n",
      "Epoch 29/50\n",
      "22925/22925 [==============================] - 10s 416us/sample - loss: 0.5603 - acc: 0.7110 - val_loss: 0.3366 - val_acc: 0.8748\n",
      "Epoch 30/50\n",
      "22925/22925 [==============================] - 9s 377us/sample - loss: 0.5587 - acc: 0.7158 - val_loss: 0.3525 - val_acc: 0.8560\n",
      "Epoch 31/50\n",
      "22925/22925 [==============================] - 8s 370us/sample - loss: 0.5528 - acc: 0.7191 - val_loss: 0.3355 - val_acc: 0.8675\n",
      "Epoch 32/50\n",
      "22925/22925 [==============================] - 9s 394us/sample - loss: 0.5555 - acc: 0.7177 - val_loss: 0.3274 - val_acc: 0.8723\n",
      "Epoch 33/50\n",
      "22925/22925 [==============================] - 8s 367us/sample - loss: 0.5489 - acc: 0.7234 - val_loss: 0.3136 - val_acc: 0.8787\n",
      "Epoch 34/50\n",
      "22925/22925 [==============================] - 8s 368us/sample - loss: 0.5453 - acc: 0.7229 - val_loss: 0.3508 - val_acc: 0.8569\n",
      "Epoch 35/50\n",
      "22925/22925 [==============================] - 8s 358us/sample - loss: 0.5441 - acc: 0.7285 - val_loss: 0.3315 - val_acc: 0.8659\n",
      "Epoch 36/50\n",
      "22925/22925 [==============================] - 8s 368us/sample - loss: 0.5412 - acc: 0.7303 - val_loss: 0.3303 - val_acc: 0.8729\n",
      "Epoch 37/50\n",
      "22925/22925 [==============================] - 9s 376us/sample - loss: 0.5367 - acc: 0.7299 - val_loss: 0.3242 - val_acc: 0.8768\n",
      "Epoch 38/50\n",
      "22925/22925 [==============================] - 9s 378us/sample - loss: 0.5387 - acc: 0.7307 - val_loss: 0.3206 - val_acc: 0.8771\n",
      "Epoch 39/50\n",
      "22925/22925 [==============================] - 9s 399us/sample - loss: 0.5377 - acc: 0.7325 - val_loss: 0.3445 - val_acc: 0.8585\n",
      "Epoch 40/50\n",
      "22925/22925 [==============================] - 9s 389us/sample - loss: 0.5264 - acc: 0.7398 - val_loss: 0.3248 - val_acc: 0.8723\n",
      "Epoch 41/50\n",
      "22925/22925 [==============================] - 9s 376us/sample - loss: 0.5233 - acc: 0.7435 - val_loss: 0.3032 - val_acc: 0.8860\n",
      "Epoch 42/50\n",
      "22925/22925 [==============================] - 9s 381us/sample - loss: 0.5214 - acc: 0.7412 - val_loss: 0.2988 - val_acc: 0.8905\n",
      "Epoch 43/50\n",
      "22925/22925 [==============================] - 8s 361us/sample - loss: 0.5243 - acc: 0.7381 - val_loss: 0.3054 - val_acc: 0.8825\n",
      "Epoch 44/50\n",
      "22925/22925 [==============================] - 9s 378us/sample - loss: 0.5189 - acc: 0.7443 - val_loss: 0.2995 - val_acc: 0.8870\n",
      "Epoch 45/50\n",
      "22925/22925 [==============================] - 9s 388us/sample - loss: 0.5194 - acc: 0.7453 - val_loss: 0.3011 - val_acc: 0.8953\n",
      "Epoch 46/50\n",
      "22925/22925 [==============================] - 9s 385us/sample - loss: 0.5202 - acc: 0.7451 - val_loss: 0.2988 - val_acc: 0.8902\n",
      "Epoch 47/50\n",
      "22925/22925 [==============================] - 8s 358us/sample - loss: 0.5183 - acc: 0.7453 - val_loss: 0.3101 - val_acc: 0.8816\n",
      "Epoch 48/50\n",
      "22925/22925 [==============================] - 8s 367us/sample - loss: 0.5070 - acc: 0.7547 - val_loss: 0.3139 - val_acc: 0.8729\n",
      "Epoch 49/50\n",
      "22925/22925 [==============================] - 8s 358us/sample - loss: 0.5074 - acc: 0.7531 - val_loss: 0.3086 - val_acc: 0.8777\n",
      "Epoch 50/50\n",
      "22925/22925 [==============================] - 8s 365us/sample - loss: 0.5025 - acc: 0.7553 - val_loss: 0.3050 - val_acc: 0.8780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23c000d6dd8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_input, train_output,\n",
    "          epochs = 50, shuffle = True,\n",
    "          validation_data = (val_input, val_output),\n",
    "          batch_size = 128,\n",
    "         use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
