{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234) ### DOES NOT WORK???\n",
    "w_length = 100\n",
    "n_countries = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only one playlist per two countries\n",
    "us = pd.read_csv(\"US_37i9dQZF1DX6bBjHfdRnza.csv\")\n",
    "mx = pd.read_csv(\"MX_37i9dQZF1DX0yN5997BIDH.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the playlists have common songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(us.track_id.isin(mx.track_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input array for US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos = list(us.track_id.index[us.track_id.shift(1) != us.track_id]) # indices where the song changes\n",
    "new_pos.append(max(us.track_id.index) + 1) # add a new index to know where the last song ends\n",
    "split_pos = []\n",
    "for i in range(len(new_pos)-1):\n",
    "    split_pos = split_pos + list(range(new_pos[i], new_pos[i+1], w_length))\n",
    "split_pos = split_pos[1:]\n",
    "us_train = np.split(us.iloc[:,:31].to_numpy(), split_pos)\n",
    "# drop the short sequences\n",
    "short_seqs = []\n",
    "temp = [] \n",
    "for i, value in enumerate(us_train):\n",
    "    if value.shape[0] == w_length:\n",
    "        temp.append(value)\n",
    "us_train = temp\n",
    "us_train = np.stack(us_train)\n",
    "val_index = np.isin(us_train[:,:,30],\n",
    "                    np.random.choice(us.track_id.unique(), np.int(len(us.track_id.unique())/10)))\n",
    "val_index = val_index.sum(1) != 0\n",
    "us_val = us_train[val_index,:,:29] # drop track id\n",
    "us_train = us_train[np.logical_not(val_index),:,:29] # drop track id\n",
    "us_train = us_train.astype(\"float64\")\n",
    "us_val = us_val.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want songs to have the same number of observations, we can determine which element in the list returned by np.slit corresponds to which song (using new_pos) and randomly overpopulate accordingly. An alternative is to do this with an online batching if we have memory problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input array for MX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos = list(mx.track_id.index[mx.track_id.shift(1) != mx.track_id]) # indices where the song changes\n",
    "new_pos.append(max(mx.track_id.index) + 1) # add a new index to know where the last song ends\n",
    "split_pos = []\n",
    "for i in range(len(new_pos)-1):\n",
    "    split_pos = split_pos + list(range(new_pos[i], new_pos[i+1], w_length))\n",
    "split_pos = split_pos[1:]\n",
    "mx_train = np.split(mx.iloc[:,:31].to_numpy(), split_pos)\n",
    "# drop the short sequences\n",
    "short_seqs = []\n",
    "temp = [] \n",
    "for i, value in enumerate(mx_train):\n",
    "    if value.shape[0] == w_length:\n",
    "        temp.append(value)\n",
    "mx_train = temp\n",
    "mx_train = np.stack(mx_train)\n",
    "val_index = np.isin(mx_train[:,:,30],\n",
    "                    np.random.choice(mx.track_id.unique(), np.int(len(mx.track_id.unique())/10)))\n",
    "val_index = val_index.sum(1) != 0\n",
    "mx_val = mx_train[val_index,:,:29] # drop track id\n",
    "mx_train = mx_train[np.logical_not(val_index),:,:29] # drop track id\n",
    "mx_train = mx_train.astype(\"float64\")\n",
    "mx_val = mx_val.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Output arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2098, 100, 29) \n",
      " (190, 100, 29) \n",
      " (2098, 2) \n",
      " (190, 2)\n",
      "float64 \n",
      " float64 \n",
      " float32 \n",
      " float32\n"
     ]
    }
   ],
   "source": [
    "train_input = np.concatenate([us_train, mx_train])\n",
    "val_input = np.concatenate([us_val, mx_val])\n",
    "\n",
    "train_output = np.ones((us_train.shape[0], 1))\n",
    "train_output = np.concatenate([train_output, np.zeros((mx_train.shape[0], 1))])\n",
    "train_output = keras.utils.to_categorical(train_output)\n",
    "val_output = np.ones((us_val.shape[0], 1))\n",
    "val_output = np.concatenate([val_output, np.zeros((mx_val.shape[0], 1))])\n",
    "val_output = keras.utils.to_categorical(val_output)\n",
    "\n",
    "\n",
    "print(train_input.shape, \"\\n\", val_input.shape, \"\\n\", train_output.shape, \"\\n\", val_output.shape)\n",
    "print(train_input.dtype, \"\\n\", val_input.dtype, \"\\n\", train_output.dtype, \"\\n\", val_output.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 25)                5500      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 5,552\n",
      "Trainable params: 5,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "out_index = 2\n",
    "model = Sequential()\n",
    "model.add(LSTM(25, input_shape=(w_length, train_input.shape[2])))\n",
    "model.add(Dense(n_countries, activation= \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer= \"adam\", metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_input)\n",
    "train_input.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2098 samples, validate on 190 samples\n",
      "Epoch 1/50\n",
      "2098/2098 [==============================] - 0s 223us/sample - loss: 0.3114 - acc: 0.8818 - val_loss: 0.3895 - val_acc: 0.8474\n",
      "Epoch 2/50\n",
      "2098/2098 [==============================] - 0s 203us/sample - loss: 0.2791 - acc: 0.9023 - val_loss: 0.3694 - val_acc: 0.8526\n",
      "Epoch 3/50\n",
      "2098/2098 [==============================] - 0s 213us/sample - loss: 0.2564 - acc: 0.9133 - val_loss: 0.3532 - val_acc: 0.8684\n",
      "Epoch 4/50\n",
      "2098/2098 [==============================] - 0s 205us/sample - loss: 0.2318 - acc: 0.9233 - val_loss: 0.3332 - val_acc: 0.8789\n",
      "Epoch 5/50\n",
      "2098/2098 [==============================] - 0s 204us/sample - loss: 0.2111 - acc: 0.9314 - val_loss: 0.3384 - val_acc: 0.8632\n",
      "Epoch 6/50\n",
      "2098/2098 [==============================] - 0s 216us/sample - loss: 0.1944 - acc: 0.9390 - val_loss: 0.3268 - val_acc: 0.8684\n",
      "Epoch 7/50\n",
      "2098/2098 [==============================] - 0s 193us/sample - loss: 0.1805 - acc: 0.9433 - val_loss: 0.3134 - val_acc: 0.8737\n",
      "Epoch 8/50\n",
      "2098/2098 [==============================] - 0s 198us/sample - loss: 0.1726 - acc: 0.9447 - val_loss: 0.3000 - val_acc: 0.8684\n",
      "Epoch 9/50\n",
      "2098/2098 [==============================] - 0s 210us/sample - loss: 0.1619 - acc: 0.9495 - val_loss: 0.3135 - val_acc: 0.8737\n",
      "Epoch 10/50\n",
      "2098/2098 [==============================] - 0s 210us/sample - loss: 0.1522 - acc: 0.9533 - val_loss: 0.2981 - val_acc: 0.8842\n",
      "Epoch 11/50\n",
      "2098/2098 [==============================] - 0s 211us/sample - loss: 0.1427 - acc: 0.9590 - val_loss: 0.2787 - val_acc: 0.8842\n",
      "Epoch 12/50\n",
      "2098/2098 [==============================] - 0s 202us/sample - loss: 0.1382 - acc: 0.9595 - val_loss: 0.2839 - val_acc: 0.8842\n",
      "Epoch 13/50\n",
      "2098/2098 [==============================] - 0s 196us/sample - loss: 0.1307 - acc: 0.9604 - val_loss: 0.2818 - val_acc: 0.8895\n",
      "Epoch 14/50\n",
      "2098/2098 [==============================] - 0s 206us/sample - loss: 0.1244 - acc: 0.9614 - val_loss: 0.2854 - val_acc: 0.8895\n",
      "Epoch 15/50\n",
      "2098/2098 [==============================] - 0s 207us/sample - loss: 0.1170 - acc: 0.9628 - val_loss: 0.2832 - val_acc: 0.9000\n",
      "Epoch 16/50\n",
      "2098/2098 [==============================] - 0s 202us/sample - loss: 0.1113 - acc: 0.9671 - val_loss: 0.2858 - val_acc: 0.9053\n",
      "Epoch 17/50\n",
      "2098/2098 [==============================] - 0s 208us/sample - loss: 0.1072 - acc: 0.9700 - val_loss: 0.2831 - val_acc: 0.9000\n",
      "Epoch 18/50\n",
      "2098/2098 [==============================] - 0s 208us/sample - loss: 0.1034 - acc: 0.9704 - val_loss: 0.2802 - val_acc: 0.9000\n",
      "Epoch 19/50\n",
      "2098/2098 [==============================] - 0s 203us/sample - loss: 0.1002 - acc: 0.9719 - val_loss: 0.2830 - val_acc: 0.9000\n",
      "Epoch 20/50\n",
      "2098/2098 [==============================] - 0s 211us/sample - loss: 0.0965 - acc: 0.9733 - val_loss: 0.2844 - val_acc: 0.9053\n",
      "Epoch 21/50\n",
      "2098/2098 [==============================] - 0s 210us/sample - loss: 0.0945 - acc: 0.9719 - val_loss: 0.2822 - val_acc: 0.8947\n",
      "Epoch 22/50\n",
      "2098/2098 [==============================] - 0s 208us/sample - loss: 0.0922 - acc: 0.9724 - val_loss: 0.2911 - val_acc: 0.8947\n",
      "Epoch 23/50\n",
      "2098/2098 [==============================] - 0s 208us/sample - loss: 0.0882 - acc: 0.9733 - val_loss: 0.2823 - val_acc: 0.8947\n",
      "Epoch 24/50\n",
      "2098/2098 [==============================] - 0s 206us/sample - loss: 0.0838 - acc: 0.9766 - val_loss: 0.2916 - val_acc: 0.9000\n",
      "Epoch 25/50\n",
      "2098/2098 [==============================] - 0s 207us/sample - loss: 0.0833 - acc: 0.9733 - val_loss: 0.2888 - val_acc: 0.8947\n",
      "Epoch 26/50\n",
      "2098/2098 [==============================] - 0s 210us/sample - loss: 0.0798 - acc: 0.9743 - val_loss: 0.2838 - val_acc: 0.8895\n",
      "Epoch 27/50\n",
      "2098/2098 [==============================] - 0s 204us/sample - loss: 0.0770 - acc: 0.9776 - val_loss: 0.2923 - val_acc: 0.9000\n",
      "Epoch 28/50\n",
      "2098/2098 [==============================] - 0s 204us/sample - loss: 0.0751 - acc: 0.9766 - val_loss: 0.2808 - val_acc: 0.8895\n",
      "Epoch 29/50\n",
      "2098/2098 [==============================] - 0s 199us/sample - loss: 0.0723 - acc: 0.9809 - val_loss: 0.2716 - val_acc: 0.8947\n",
      "Epoch 30/50\n",
      "2098/2098 [==============================] - 0s 201us/sample - loss: 0.0696 - acc: 0.9805 - val_loss: 0.2849 - val_acc: 0.8895\n",
      "Epoch 31/50\n",
      "2098/2098 [==============================] - 0s 208us/sample - loss: 0.0681 - acc: 0.9814 - val_loss: 0.2812 - val_acc: 0.8947\n",
      "Epoch 32/50\n",
      "2098/2098 [==============================] - 0s 204us/sample - loss: 0.0654 - acc: 0.9824 - val_loss: 0.2779 - val_acc: 0.8947\n",
      "Epoch 33/50\n",
      "2098/2098 [==============================] - 0s 200us/sample - loss: 0.0628 - acc: 0.9824 - val_loss: 0.2826 - val_acc: 0.8895\n",
      "Epoch 34/50\n",
      "2098/2098 [==============================] - 0s 208us/sample - loss: 0.0610 - acc: 0.9838 - val_loss: 0.2855 - val_acc: 0.8895\n",
      "Epoch 35/50\n",
      "2098/2098 [==============================] - 0s 210us/sample - loss: 0.0593 - acc: 0.9847 - val_loss: 0.2831 - val_acc: 0.8895\n",
      "Epoch 36/50\n",
      "2098/2098 [==============================] - 0s 198us/sample - loss: 0.0580 - acc: 0.9857 - val_loss: 0.2845 - val_acc: 0.8947\n",
      "Epoch 37/50\n",
      "2098/2098 [==============================] - 0s 199us/sample - loss: 0.0573 - acc: 0.9843 - val_loss: 0.2795 - val_acc: 0.8895\n",
      "Epoch 38/50\n",
      "2098/2098 [==============================] - 0s 204us/sample - loss: 0.0553 - acc: 0.9867 - val_loss: 0.2827 - val_acc: 0.8895\n",
      "Epoch 39/50\n",
      "2098/2098 [==============================] - 0s 210us/sample - loss: 0.0537 - acc: 0.9881 - val_loss: 0.2834 - val_acc: 0.8947\n",
      "Epoch 40/50\n",
      "2098/2098 [==============================] - 0s 209us/sample - loss: 0.0527 - acc: 0.9871 - val_loss: 0.2841 - val_acc: 0.8895\n",
      "Epoch 41/50\n",
      "2098/2098 [==============================] - 0s 208us/sample - loss: 0.0510 - acc: 0.9890 - val_loss: 0.2859 - val_acc: 0.8895\n",
      "Epoch 42/50\n",
      "2098/2098 [==============================] - 0s 201us/sample - loss: 0.0492 - acc: 0.9886 - val_loss: 0.2922 - val_acc: 0.8895\n",
      "Epoch 43/50\n",
      "2098/2098 [==============================] - 0s 199us/sample - loss: 0.0486 - acc: 0.9886 - val_loss: 0.2958 - val_acc: 0.8895\n",
      "Epoch 44/50\n",
      "2098/2098 [==============================] - 0s 205us/sample - loss: 0.0475 - acc: 0.9900 - val_loss: 0.2842 - val_acc: 0.8842\n",
      "Epoch 45/50\n",
      "2098/2098 [==============================] - 0s 202us/sample - loss: 0.0461 - acc: 0.9895 - val_loss: 0.2831 - val_acc: 0.8947\n",
      "Epoch 46/50\n",
      "2098/2098 [==============================] - 0s 205us/sample - loss: 0.0445 - acc: 0.9909 - val_loss: 0.2788 - val_acc: 0.9000\n",
      "Epoch 47/50\n",
      "2098/2098 [==============================] - 0s 200us/sample - loss: 0.0468 - acc: 0.9890 - val_loss: 0.2802 - val_acc: 0.8947\n",
      "Epoch 48/50\n",
      "2098/2098 [==============================] - 0s 198us/sample - loss: 0.0461 - acc: 0.9905 - val_loss: 0.2737 - val_acc: 0.9000\n",
      "Epoch 49/50\n",
      "2098/2098 [==============================] - 0s 203us/sample - loss: 0.0430 - acc: 0.9914 - val_loss: 0.2726 - val_acc: 0.9158\n",
      "Epoch 50/50\n",
      "2098/2098 [==============================] - 0s 215us/sample - loss: 0.0411 - acc: 0.9919 - val_loss: 0.2755 - val_acc: 0.9158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25f2fccbdc8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_input, train_output,\n",
    "          epochs = 50, shuffle = True,\n",
    "          validation_data = (val_input, val_output),\n",
    "          batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
