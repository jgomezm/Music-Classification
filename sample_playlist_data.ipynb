{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code identifies the tracks in a playlist and then retrieves audio_analysis data for them. The dataset analyzes the track in two different ways. One way is listing duration of tatums (bars and beats are very similar concepts but tatum is more specific, leading to more observations). The other representation is splitting the track in musically similar parts (sections or segments, segment being more specific). A segment contains 30 features including its duration, loudness, pitch and timbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(\n",
    "        \"26399552a8ce4d1285397254189cac50\",\n",
    "        \"fdacbbba2dd34dbeb127dedb459f7ea3\")\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the track IDs in Germany Top 50\n",
    "ger_pl = sp.playlist(\"spotify:playlist:37i9dQZEVXbJiZcmkrIHGU\")\n",
    "ger_t_list = []\n",
    "for track in ger_pl[\"tracks\"][\"items\"]:\n",
    "    ger_t_list = ger_t_list + [track[\"track\"][\"uri\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['meta', 'track', 'bars', 'beats', 'tatums', 'sections', 'segments'])\n"
     ]
    }
   ],
   "source": [
    "# Audio analysis of a sample track\n",
    "audio = sp.audio_analysis(ger_t_list[0])\n",
    "print(audio.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max difference between the end of a tatum and the start of the next is:  1e-05\n"
     ]
    }
   ],
   "source": [
    "# Beats are subdivisions of bars. Tatums are subdivisions of beats.\n",
    "tatum_data = pd.DataFrame(audio[\"tatums\"])\n",
    "tatum_data = tatum_data.assign(end = tatum_data.start + tatum_data.duration)\n",
    "# Just a check to see if a tatum ends before the next\n",
    "print(\"Max difference between the end of a tatum and the start of the next is: \",\n",
    "      '{:.5}'.format((tatum_data.start - tatum_data.end.shift()).max()))\n",
    "# Sequence with only one series (tatum durations). Could be used to train a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_id\n",
      "spotify:track:07f2b3CTdgKKlhv0mqUksz     667\n",
      "spotify:track:0C6bsQq58Ue1XfL5PKTO6D     649\n",
      "spotify:track:0LPRq5I35z8FoqYo84xn48     933\n",
      "spotify:track:0Vl4eICpXMjtiK0RhdaWov     805\n",
      "spotify:track:0dv22i02nk3o8JwmK6BwjI     723\n",
      "spotify:track:0nbXyq5TXYPCO7pr3N8S4I     751\n",
      "spotify:track:0oFrTaO9UIgqu6MuzkFu7B     689\n",
      "spotify:track:0sf12qNH5qcw8qpgymFOqD     772\n",
      "spotify:track:0ui2kVwPZKHaZxGhdIzBrp     940\n",
      "spotify:track:16wAOAZ2OkqoIDN7TpChjR     812\n",
      "spotify:track:1B89LtaW92jj4AqT7OZ0Fj     875\n",
      "spotify:track:1E1YyZjbteIz2XQyLvtRxD     759\n",
      "spotify:track:1R4xkZXQUQ8QJtAdwHkSgC     651\n",
      "spotify:track:1V7JaMp11LKGwKiVmSetf0     678\n",
      "spotify:track:1hoLUVBx0ixX3kn0EX0P5n     692\n",
      "spotify:track:1rgnBhdG2JDFTbYkYRZAku     754\n",
      "spotify:track:24Yi9hE78yPEbZ4kxyoXAI     776\n",
      "spotify:track:2GdDsXV5v47AZsuwtGjKKy     815\n",
      "spotify:track:2PGA1AsJal6cyMNmKyE56q     760\n",
      "spotify:track:2RaKlveGCllSaXloN8kmzV     805\n",
      "spotify:track:2fzPZOozISzcAU7FSwkN7g     737\n",
      "spotify:track:2rWnTpXD0jq5lymyg4xIKQ     642\n",
      "spotify:track:2tnVG71enUj33Ic2nFN6kZ     783\n",
      "spotify:track:36J10AwMabBYxgNrV2S8gd     752\n",
      "spotify:track:38YP1STiBe3AZevFFJILf4     707\n",
      "spotify:track:3H7ihDc1dqLriiWXwsc2po     671\n",
      "spotify:track:3ZCTVFBt2Brf31RLEnCkWJ     970\n",
      "spotify:track:3cqPu20DGTGUoZtbJH2Dmi     655\n",
      "spotify:track:3ecKtWMr8HK99YOs7L6Ps3     835\n",
      "spotify:track:4OVF6uwZlMOSlZmHDnwliX     831\n",
      "spotify:track:4TnjEaWOeW0eKTKIEvJyCa     558\n",
      "spotify:track:4umIPjkehX1r7uhmGvXiSV     932\n",
      "spotify:track:5XVPNr0CAoUn1jD033Ucoo     799\n",
      "spotify:track:5yY9lUy8nbvjM1Uyo1Uqoc    1054\n",
      "spotify:track:61ZM92T2zaXIVsqncThQzC     765\n",
      "spotify:track:67ojvEGRPAUCOohuMPqoRC     812\n",
      "spotify:track:696DnlkuDOXcMAnKlTgXXK     674\n",
      "spotify:track:6JZrs7FFUkTpinCxM1DG3E     883\n",
      "spotify:track:6Q2CA0eSQcQsue63QwnLnB     757\n",
      "spotify:track:6WrI0LAC5M1Rw2MnX2ZvEg     764\n",
      "spotify:track:6a1eOZTiZdgFRUOnMBjT4j     988\n",
      "spotify:track:6dNB3XdAzx7kTf5wa8Rg89     702\n",
      "spotify:track:6hw1Sy9wZ8UCxYGdpKrU6M     716\n",
      "spotify:track:6mPETBNZFx2xjCR2YFPfcj     756\n",
      "spotify:track:73SpzrcaHk0RQPFP73vqVR     706\n",
      "spotify:track:76IVpz47q3ghkxoUeTTEKb     832\n",
      "spotify:track:7CHi4DtfK4heMlQaudCuHK     583\n",
      "spotify:track:7Ek9e3eIuktIFjpDRQfmHE    1084\n",
      "spotify:track:7FIWs0pqAYbP91WWM0vlTQ    1033\n",
      "spotify:track:7N06jo3EnV792VFaG8vuW6     689\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Audio segments attempts to subdivide a song into many segments, with each \n",
    "# segment containing a roughly consistent sound throughout its duration.\n",
    "# A segment contains 30 features.\n",
    "ger_data = pd.DataFrame()\n",
    "for track in ger_t_list:\n",
    "    audio = sp.audio_analysis(track)\n",
    "    segments_data =  pd.DataFrame(audio[\"segments\"])\n",
    "    pitch = segments_data.pitches.apply(pd.Series)\n",
    "    pitch.columns = [\"p\" + str(i) for i in range(1,13)]\n",
    "    timbre = segments_data.timbre.apply(pd.Series)\n",
    "    timbre.columns = [\"t\" + str(i) for i in range(1,13)]\n",
    "    segments_data = segments_data.drop([\"pitches\", \"timbre\", \"loudness_end\"],\n",
    "                                       axis = 1)\n",
    "    segments_data = segments_data.join([pitch, timbre])\n",
    "    segments_data[\"track_id\"] = track\n",
    "    ger_data = ger_data.append(segments_data)\n",
    "print(ger_data.groupby(\"track_id\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['start', 'duration', 'confidence', 'loudness_start',\n",
      "       'loudness_max_time', 'loudness_max', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6',\n",
      "       'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 't1', 't2', 't3', 't4', 't5',\n",
      "       't6', 't7', 't8', 't9', 't10', 't11', 't12', 'track_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ger_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitch\n",
    "Pitch content is given by a “chroma” vector, corresponding to the 12 pitch classes C, C#, D to B, with values ranging from 0 to 1 that describe the relative dominance of every pitch in the chromatic scale. For example a C Major chord would likely be represented by large values of C, E and G (i.e. classes 0, 4, and 7). Vectors are normalized to 1 by their strongest dimension, therefore noisy sounds are likely represented by values that are all close to 1, while pure tones are described by one value at 1 (the pitch) and others near 0. https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timbre\n",
    "Timbre is the quality of a musical note or sound that distinguishes different types of musical instruments, or voices. It is a complex notion also referred to as sound color, texture, or tone quality, and is derived from the shape of a segment’s spectro-temporal surface, independently of pitch and loudness. The timbre feature is a vector that includes 12 unbounded values roughly centered around 0. Those values are high level abstractions of the spectral surface, ordered by degree of importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
